---
title: INF0613 -- Aprendizado de Máquina Não Supervisionado
output: pdf_document
subtitle: Trabalho 1 - Regras de Associação
author: 
  - Vitor de Oliveira Fernandez Araujo
  - Vitor Sancho Cardoso
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, error = FALSE, message = FALSE, warning = FALSE, tidy = FALSE)
options(digits = 3)
```

Neste primeiro trabalho, vamos minerar Regras de Associação em uma base de dados que contém as vendas de uma padaria. A base de dados está disponível na página da disciplina no Moodle (arquivo `bakery.csv`).

# Atividade 0 -- Configurando o ambiente
Antes de começar a implementação do seu trabalho configure o _workspace_ e importe todos os pacotes:

```{r atv0-code}
# Adicione os demais pacotes usados
# Bibliotecas usadas neste trabalho:
library(arules)

# Configurando ambiente de trabalho:
# setwd("")

```


# Atividade 1 -- Análise Exploratória da Base de Dados (*3,0 pts*)

Dado um caminho para uma base de dados, leia as transações e faça uma análise Exploratória sobre elas. Use as funções `summary`,  `inspect` e `itemFrequencyPlot`. Na função `inspect`, limite sua análise às 10 primeiras transações e na função `itemFrequencyPlot` gere um gráfico com a frequência relativa dos 30 itens mais frequentes. 

```{r atv1-code}
# Ler transações
con <- file("bakery.csv", open = "r")
dados_bakery <- read.transactions(con, format="basket", sep=",")

# Visualizando transações
inspect(head(dados_bakery, 10))

# Sumário da base
summary(dados_bakery)

# Analisando a frequência dos itens 
itemFrequencyPlot(dados_bakery, topN = 30)

itemFrequencyPlot(dados_bakery, topN = 30, type = "absolute")

itemFrequencyPlot(dados_bakery, support=0.1, topN=30)

itemFrequencyPlot(dados_bakery, support=0.07, topN=30)

itemFrequencyPlot(dados_bakery, support=0.05, topN=30)

itemFrequencyPlot(dados_bakery, support=0.025, topN=30)

```


## Análise 

a) Descreva a base de dados discutindo os resultados das funções acima. 

**Resposta:** <!-- Escreva sua resposta abaixo -->
A base de dados é composta por registros/transações de compras em uma padaria. Cada registro é uma lista de itens de uma determinada compra. O nosso dataset possui 2579 registros de compras e um total de 91 colunas (que se refletem em itens disponíveis para compra na padaria). Podemos notar que essa padaria tem um grande volume de compras com poucos itens, a maior quantidade de compras possui entre 1 e 4 itens. Das 2579  compras, em somente 7 compras clientes adquiriram mais do que 7 itens. Isso nos dá margem para criar a hipótese dessa ser uma padaria pequena, para compras rápidas, onde os clientes buscam comprar itens para o café da manhã ou um lanche que seja servido pela própria padaria ou que possam levar esses itens para casa. O items mais frequentes nas listas de compra são o café (presente), pão, chá e bolo, o que reforça a nossa hipótese sobre o perfil da padaria. O que não nos permite confirmar isso é a falta de uma maior qualificação dos dados.
<!-- Fim da resposta -->

b) Ao gerarmos o gráfico de frequências, temos uma representação visual de uma informação já presente no resultado da função `summary`. Contudo, esse gráfico nos dá uma visão mais ampla da base. Assim, podemos ver a frequência de outros itens em relação aos 10 mais frequentes. Quais informações podemos obter a partir desse gráfico (e da análise anterior) para nos ajudar na extração de regras de associação com o algoritmo `apriori`? Isto é, como a frequência dos itens pode afetar os parâmetros de configuração do algoritmo `apriori`? 

**Resposta:** <!-- Escreva sua resposta abaixo -->
O gráfico nos permite ter uma noção mais fácil da relação quantitiva e relativa entre os itens presentes em nas transações. Ele pode nos ajudar a configurar alguns parametros do algoritmo apriori, como o suporte e a confiança. Olhando para o histograma podemos dizer que não podemos usar um valor alto de suporte, pois muitos itens disponíveis na padaria são comprados com pouca frequência, por isso seriam ignorados pela analise. 
Além disso, não podemos usar uma confiança muito alta de forma que somente regras muito fortes sejam analisadas. Isso provavelmente resultaria em regras que apresentam somente os itens mais frequentes das transações.
(não sei se temos que falar sobre min e max lenght, mas se acharmos uma boa já tá aí>)
Sobre o tamanho mínimo e máximo das relações, como estamos interessados em observar a relação entre os itens, podemos usar 2 como valor mínimo. Para o valor máximo podemos usar 5, pois a partir de 6 itens temos uma quantidade muito pequena de compras.
<!-- Fim da resposta -->

# Atividade 2 -- Minerando Regras (*3,5 pts*)

Use o algoritmo `apriori` para minerar regras na base de dados fornecida. Experimente com pelo menos *3 conjuntos* de valores diferentes de suporte e confiança para encontrar regras de associação. Imprima as cinco regras com o maior confiança de cada conjunto escolhido.  Lembre-se de usar seu conhecimento sobre a base, obtido na questão anterior, para a escolha dos valores de suporte e confiança.

```{r atv2-code}
# Conjunto 1: suporte =  0.01 e confiança = 0.6   
conjunto1 <- apriori(dados_bakery,
                   parameter = list(support = 0.01, confidence = 0.6))
inspect(head(sort(conjunto1, by = "confidence"), 5))

# Conjunto 2: suporte =  0.02  e confiança = 0.3   
conjunto2 <- apriori(dados_bakery,
                   parameter = list(support = 0.02, confidence = 0.3))
inspect(head(sort(conjunto2, by = "confidence"), 5))

# Conjunto 3: suporte = 0.01 e confiança =  0.6
conjunto3 <- apriori(dados_bakery,
                   parameter = list(support = 0.01, confidence = 0.6))
inspect(head(sort(conjunto3, by = "confidence"), 5))

```

## Análises 
a) Quais as regras mais interessantes geradas a partir dessa base? Justifique.

**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

# Atividade 3 -- Medidas de Interesse (*3,5 pts*)

Vimos na aula que, mesmo após as podas do algoritmo `apriori`, ainda temos algumas regras com características indesejáveis como redundâncias e dependência estatística negativa. Também vimos algumas medidas que nos ajudam a analisar melhor essas regras como o lift, a convicção e a razão de chances. Nesta questão, escolha um dos conjuntos de regras geradas na atividade anterior e o analise usando essas medidas. Compute as três medidas para o conjunto escolhido com a função `interestMeasure` e experimente ordenar as regras com cada uma das novas medidas.

Dica: para adicionar as medidas em um conjunto de regras qualquer, você pode utilizar o comando `cbind` e a função `quality`:
```
quality(regras) <- cbind(quality(regras), interestMeasure(regras, measure=c("conviction", "oddsRatio"), 
                                          transactions = transacoes))
```


```{r atv3-code}
# Compute as medidas de interesse 


# Apresente as regras ordenadas por lift

# Apresente as regras ordenadas por convicção

# Apresente as regras ordenadas por razão de chances


```


## Análise 
a) Quais as regras mais interessantes do conjunto? Justifique.

**Resposta:** <!-- Escreva sua resposta abaixo -->


<!-- Fim da resposta -->

