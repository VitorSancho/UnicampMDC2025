---
title: INF0615 -- Aprendizado de Máquina Supervisionado I
output: pdf_document
subtitle: Trabalho 1 - Predição de Calorias
author: 
  - Vitor de Oliveira Fernandez Araujo
  - Vitor Sancho Cardoso
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo    = TRUE,   # Exibir código nos chunks
  error   = FALSE,  # Ocultar mensagens de erro
  message = FALSE,  # Ocultar mensagens informativas
  warning = FALSE,  # Ocultar avisos
  tidy    = FALSE   # Não reformatar automaticamente o código
)

options(digits = 4) # Definição do número de casas decimais padrão
```

Neste primeiro trabalho, exploraremos a predição de calorias que um indivíduo gastou durante um exercício, utilizando regressão linear. O conjunto de dados está disponível na página da disciplina no Moodle (arquivo `T01_SPLIT_set.csv`).

# Função de apoio

```{r}
# A funcao abaixo auxilia na escrita dos modelos polinomiais. 
# Parametros:
#  "real_feature_names": conjunto de features continuas que sera considerado na
#                        criacao do modelo polinomial.
#
#  "categorical_feature_names": conjunto de features categoricas que sera 
#                               considerado na  criacao do modelo polinomial. Se
#                                voces desejarem um modelo sem variaveis categoricas
#                               basta nao passar nenhum valor para este parametro
#                               na chamada da funcao
#                       
# "degree": numero inteiro que indica ate qual grau polinomial as features continuas
#           em "real_feature_names" serao elevadas. 
#
# A funcao retorna a hipotese ja definida para realizar o treinamento do modelo. 
# Uma ilustracao de uma funcao similar aparece no Ex02.R na linha 490

getHypothesis <- function(real_feature_names, categorical_feature_names=F, target="Calorias", degree=3){
    
    hypothesis_string <- paste("hypothesis <- formula(", target, " ~ ")
    for(d in 1:degree){
        for(i in 1:length(real_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       "I(", real_feature_names[i], "^", d, ") + ",
                                       sep = "")
        }
    }
    
    if(typeof(categorical_feature_names) != "logical"){
        for(i in 1:length(categorical_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       categorical_feature_names[i], " + ",
                                       sep = "")
        } 
    }
    
    
    hypothesis_string <- substr(hypothesis_string, 1, nchar(hypothesis_string)-3)
    hypothesis_string <- paste(hypothesis_string, ")")
    hypothesis <- eval(parse(text=hypothesis_string))
    return(hypothesis)
}
```

# Tarefa 0 -- Configurando o ambiente

Carregue as bibliotecas necessárias e defina uma semente aleatória para garantir a reprodutibilidade dos experimentos.

```{r atv0-code}
# Adicione as bibliotecas necessárias
library(ggplot2)
library(corrplot)
set.seed(42)
```

# Tarefa 1 -- Inspeção de Dados e Normalização

Carreguem e inspecionem o conjunto de dados. Além disso, prepare os dados corretamente para utilizá-los como entrada para um modelo de regressão linear.

```{r atv1-code}
# Carregue o conjunto de dados
dados_treino <- read.csv("T01_train_set.csv")
dados_validacao <- read.csv("T01_valid_set.csv")

# Sumário da base pré limpeza
paste("O dataframe de TREINO possui",nrow(dados_treino),"registros",sep=" ")
paste("summary TREINO:")
summary(dados_treino)
paste("####################################################################")
paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao),"registros",sep=" ")
paste("summary VALIDAÇÃO:")
summary(dados_validacao)

dados_treino_sem_NAs <- dados_treino[
  !is.na(dados_treino$Genero) & 
  !is.na(dados_treino$Altura) & 
  !is.na(dados_treino$Peso) & 
  !is.na(dados_treino$Batimento.Cardiaco) & 
  !is.na(dados_treino$Idade),]

dados_validacao_sem_NAs <- dados_validacao[
  !is.na(dados_validacao$Duracao) & 
  !is.na(dados_validacao$Temperatura.Corporal)&
  !is.na(dados_validacao$Peso),]
paste("####################################################################")
paste("####################################################################")

# Sumário da base pós limpeza
paste("O dataframe de TREINO possui",nrow(dados_treino_sem_NAs),"registros após a limpeza",sep=" ")
paste("summary TREINO:")
summary(dados_treino_sem_NAs)
NAs_removidos_treino <- nrow(dados_treino) - nrow(dados_treino_sem_NAs)
paste("Foram removidos",NAs_removidos_treino,
      " registros inválidos do dataset de TREINO", sep=" ")
paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao_sem_NAs),"registros após a limpeza",sep=" ")
paste("####################################################################")
paste("summary VALIDAÇÃO:")
summary(dados_validacao_sem_NAs)
NAs_removidos_validacao <- nrow(dados_validacao) - nrow(dados_validacao_sem_NAs)
paste("Foram removidos",NAs_removidos_validacao,
      " registros inválidos do dataset de VALIDAÇÃO", sep=" ")
paste("####################################################################")
paste("####################################################################")

# One Hot Encoding
paste("One hot encoding para conjunto de TREINO")
dados_para_encoding_treino <- dados_treino_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, genero_one_hot_encoding)

dados_para_encoding_treino$Idade <- NULL
dados_para_encoding_treino$Genero <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

paste("One hot encoding para conjunto de VALIDAÇÃO")

dados_para_encoding_validacao <- dados_validacao_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, genero_one_hot_encoding)

dados_para_encoding_validacao$Idade <- NULL
dados_para_encoding_validacao$Genero <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))
paste("####################################################################")
paste("####################################################################")

# Normalização
dados_treino_para_normalizacao <- dados_para_encoding_treino
dados_validacao_para_normalizacao <- dados_para_encoding_validacao
min_features <- apply(dados_treino_para_normalizacao[, 1:6], 2, min)
max_features <- apply(dados_treino_para_normalizacao[, 1:6], 2, max)
diff         <- max_features - min_features

treino_normalizado <- dados_treino_para_normalizacao
validacao_normalizado <- dados_validacao_para_normalizacao

treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, min_features, "-")
treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, diff, "/")

validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, min_features, "-")
validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, diff, "/")
paste("####################################################################")

# Análise da distribuição dos dados de treino
ggplot(dados_treino_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_treino_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_treino_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_treino_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_treino_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_treino_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_treino_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

paste("#####################################################################")
paste("#####################################################################")
paste("#####################################################################")

# Distribuição dos dados de valição

ggplot(dados_validacao_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_validacao_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_validacao_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_validacao_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_validacao_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_validacao_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_validacao_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

paste("#####################################################################")
paste("#####################################################################")

# Calculando a matriz de correlação
correlation <- cor(treino_normalizado[,c(1:6, 13:14)])
print(correlation)

corrplot(correlation, method = "color", type = "upper",
         addCoef.col = "black", tl.col = "black", tl.srt = 45, number.cex = 1)

```

1.1 -- Quantas amostras existem no conjunto de dados? Como vocês lidarão com features categóricas, caso existam?
**Resposta:**
O dataframe de treino possui 10513 registros, já o de validação possui 2260 registros. 
Identificamos que as features Genero e Idade são catagóricas. Com elas realizamos o processo de one hot encoding, em que 
foram criadas uma coluna para cada valor discreto possível para essas features.
<!-- Fim da resposta -->

1.2 -- Existem amostras com valores ausentes? Como vocês pretendem tratar esses casos?
**Resposta:**
Desses dataframes, foram removidos os registros inválidos, após esse processo o dataframe de treino ficou com 8729 registros e o de validação com 1914 registros.
<!-- Fim da resposta -->

1.3 -- Há alguma característica dos dados que pode impactar o desempenho do modelo?
**Resposta:**
Realizamos o plot da matriz de correlação das features contidas no dataset. Observamos que as features Peso e Altura tem uma baixíssima correlação com 
a feature de Calorias, sendo um valor de 0.03 e 0.02 respectivamente. Com isso, podemos afirmar que a presença dessas features não será ajuda a explicar
a variação da feature de resposta do modelo, que é Calorias.
Sobre a distribuição dos dados é possível notar que as features de altura, peso e batimento cardíaco se assemelham muito com uma gaussiana. A de temperatura corporal é uma gaussiana com Assimetria positiva, ou seja, com uma cauda longa à esquerda do valor da mediana dos dados. Para a feature de duração de exercícios temos quase uma distribuição uniforme dos valores, sendo a única exceção os extremos superiores e inferiores dos dados, que possuem um valor de frequência prómixo a metade dos demais. A distribuição da feature de gênero nos indica que os dois valores presenter no dataset possuem uma contagem muito próxima, não demonstrando qualquer desbalanceamento entre essas classes. Já a feature de idade mostra um decaimento na contagem de registros conforme a faixa de idade aumenta, indicando que o total de registros contidos das faixas de 20-29 e 30-39 anos é quase igual a soma das demais faixas.
<!-- Fim da resposta -->

# Tarefa 2 -- Modelo Baseline

Treinem um modelo baseline de regressão linear utilizando **todas as features disponíveis**.

```{r atv2-code}
# Função para calcular o MAE
MAE <- function(preds, labels) {
  mae_values <- sum(abs(preds - labels)) / length(preds)
  return(mae_values)
}

# Função para calcular o MSE
MSE <- function(preds, labels) {
  mse_values <- sum((preds - labels)^2) / length(preds)
  return(mse_values)
}

# Função para calcular o R²
R2 <- function(pred, true) {
  rss <- sum((pred - true)^2)
  tss <- sum((true - mean(true))^2)
  r2 <- 1 - rss / tss
  return(r2)
}

# Treinamento    
baseline <- lm(formula = Calorias ~ Altura + Peso
               + Duracao + Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 +
                 Idade30_39 +
                 Idade40_49 +
                 Idade50_59 +
                  Idade60_69 +
                 Idade70_79 +
                 Generofeminino + 
                 Generomasculino
               ,data=treino_normalizado)

# Avaliação do Modelo
model_metrics <- function(train_set, validation_set, model){
  # Realizando previsões nos dados de treino e validação
  train_pred <- predict(model, train_set)
  valid_pred <- predict(model, validation_set)
  
  # Calculando as métricas para o conjunto de treino
  mae_train <- MAE(train_pred, train_set$Calorias)
  mse_train <- MSE(train_pred, train_set$Calorias)
  r2_train  <- R2(train_pred, train_set$Calorias)
  
  # Calculando as métricas para o conjunto de validação
  mae_valid <- MAE(valid_pred, validation_set$Calorias)
  mse_valid <- MSE(valid_pred, validation_set$Calorias)
  r2_valid  <- R2(valid_pred, validation_set$Calorias)
  
  
  # Organizando os resultados em um dataframe
  results_baseline <- data.frame(
    Metric = c("MAE", "MSE", "R2"),
    Train = c(mae_train, mse_train, r2_train),
    Valid = c(mae_valid, mse_valid, r2_valid)
  )
  
  # Formatando os resultados para melhor leitura
  results_baseline$Train <- as.numeric(results_baseline$Train)
  results_baseline$Valid <- as.numeric(results_baseline$Valid)
  
  # Evitando notação científica na exibição dos resultados
  results_baseline$Train <- format(results_baseline$Train, scientific = FALSE)
  results_baseline$Valid <- format(results_baseline$Valid, scientific = FALSE)
  
  # Exibindo os resultados
  results_baseline
}

model_metrics(treino_normalizado, validacao_normalizado, baseline)
```

2.1 -- O modelo baseline foi suficiente para resolver o problema? Quais métricas de avaliação vocês utilizaram para justificar a resposta?

**Resposta:** 
O modelo base apresentou um bom desempenho para explicar o comportamento dos dados. A métrica de erro absoluto médio atingiu 0.026856 e o coeficiente de determincação
atingiu valor de 0.966849, mostrando que a variância da feature Calorias é bem explicada pelas demais features do dataset.
<!-- Fim da resposta -->

# Tarefa 3 -- Combinação de Features

Implementem soluções alternativas baseadas em regressão linear através da combinação das features existentes para melhorar o resultado do *baseline*. Comparem suas soluções reportando os erros no **conjunto validação**. Vocês podem solicitar ajuda de uma LLM (Maritca AI, ChatGPT, DeepSeek, etc) se preferirem.

**Lembrem-se que as features categóricas podem ser incluída no modelo mas fora do processo de combinação**. Vejam o Ex01.R como referência.

```{r atv3-code}
# Hipóteses alternativas

# Treinamento

# Métricas de avaliação

# Curva de viés e variância
```

3.1 -- Quais foram os critérios utilizados para selecionar as combinações de features?

3.2 -- Alguma combinação gerou um impacto positivo ou negativo significativo no desempenho do modelo? Por quê?

3.3 -- Existe alguma relação entre viés e variância no seu modelo ao modificar as combinações de features?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 4 -- Modelos Polinomiais

Implementem soluções alternativas baseadas em regressão linear aumentando os graus das features (regressão com polinômios) para melhorar o resultado obtido no baseline. Plotem o erro no conjunto de treinamento e validação pelo grau do polinômio.

```{r atv4-code}
# Hipóteses polinomiais

# Treinamento

# Métricas de avaliação

# Curva de viés e variância
```

4.1 -- Como o grau do polinômio afetou o desempenho do modelo?

4.2 -- Houve um ponto ótimo onde o erro foi minimizado? Como vocês identificaram esse ponto?

4.3 -- Em quais regiões da curva de viés e variância foi possível identificar underfitting e overfitting?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 5 -- Conjunto de Teste

Após identificar o melhor modelo, utilizem-no para fazer previsões no conjunto de teste e avaliem o seu desempenho.

```{r atv5-code}
# Predição

# Métricas de avaliação
```

5.1 -- Qual foi o critério adotado para definir o melhor modelo?

5.2 -- Como os resultados no conjunto de teste se comparam aos obtidos no conjunto de validação? Houve algum indício degradação ou melhora do modelo?

5.3 -- Expliquem a diferença entre os modelos e o porquê que estas diferenças levaram a resultados piores ou melhores.

5.4 -- Considerando as diferentes abordagens testadas, quais estratégias poderiam ser aplicadas para melhorar ainda mais o desempenho do modelo?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Observações Finais

Justifiquem suas escolhas com base em evidências (métricas, gráficos, hipóteses teóricas).

A clareza na comunicação dos resultados é mais importante do que a qualidade do modelo!
