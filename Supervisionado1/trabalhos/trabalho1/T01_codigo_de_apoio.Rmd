---
title: INF0615 -- Aprendizado de Máquina Supervisionado I
output: pdf_document
subtitle: Trabalho 1 - Predição de Calorias
author: 
  - Vitor de Oliveira Fernandez Araujo
  - Vitor Sancho Cardoso
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo    = TRUE,   # Exibir código nos chunks
  error   = FALSE,  # Ocultar mensagens de erro
  message = FALSE,  # Ocultar mensagens informativas
  warning = FALSE,  # Ocultar avisos
  tidy    = FALSE   # Não reformatar automaticamente o código
)

options(digits = 4) # Definição do número de casas decimais padrão
```

Neste primeiro trabalho, exploraremos a predição de calorias que um indivíduo gastou durante um exercício, utilizando regressão linear. O conjunto de dados está disponível na página da disciplina no Moodle (arquivo `T01_SPLIT_set.csv`).

# Função de apoio

```{r}
# A funcao abaixo auxilia na escrita dos modelos polinomiais. 
# Parametros:
#  "real_feature_names": conjunto de features continuas que sera considerado na
#                        criacao do modelo polinomial.
#
#  "categorical_feature_names": conjunto de features categoricas que sera 
#                               considerado na  criacao do modelo polinomial. Se
#                                voces desejarem um modelo sem variaveis categoricas
#                               basta nao passar nenhum valor para este parametro
#                               na chamada da funcao
#                       
# "degree": numero inteiro que indica ate qual grau polinomial as features continuas
#           em "real_feature_names" serao elevadas. 
#
# A funcao retorna a hipotese ja definida para realizar o treinamento do modelo. 
# Uma ilustracao de uma funcao similar aparece no Ex02.R na linha 490

getHypothesis <- function(real_feature_names, categorical_feature_names=F, target="Calorias", degree=3){
    
    hypothesis_string <- paste("hypothesis <- formula(", target, " ~ ")
    for(d in 1:degree){
        for(i in 1:length(real_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       "I(", real_feature_names[i], "^", d, ") + ",
                                       sep = "")
        }
    }
    
    if(typeof(categorical_feature_names) != "logical"){
        for(i in 1:length(categorical_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       categorical_feature_names[i], " + ",
                                       sep = "")
        } 
    }
    
    
    hypothesis_string <- substr(hypothesis_string, 1, nchar(hypothesis_string)-3)
    hypothesis_string <- paste(hypothesis_string, ")")
    hypothesis <- eval(parse(text=hypothesis_string))
    return(hypothesis)
}
```

# Tarefa 0 -- Configurando o ambiente

Carregue as bibliotecas necessárias e defina uma semente aleatória para garantir a reprodutibilidade dos experimentos.

```{r atv0-code}
# Adicione as bibliotecas necessárias
library(ggplot2)
library(reshape2)
library(corrplot)
set.seed(42)
```

# Tarefa 1 -- Inspeção de Dados e Normalização

Carreguem e inspecionem o conjunto de dados. Além disso, prepare os dados corretamente para utilizá-los como entrada para um modelo de regressão linear.

```{r atv1-code}
# Carregue o conjunto de dados
dados_treino <- read.csv("T01_train_set.csv")
dados_validacao <- read.csv("T01_valid_set.csv")

# Sumário da base pré limpeza
paste("O dataframe de TREINO possui",nrow(dados_treino),"registros",sep=" ")
paste("summary TREINO:")
summary(dados_treino)
paste("####################################################################")
paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao),"registros",sep=" ")
paste("summary VALIDAÇÃO:")
summary(dados_validacao)

dados_treino_sem_NAs <- dados_treino[
  !is.na(dados_treino$Genero) & 
  !is.na(dados_treino$Altura) & 
  !is.na(dados_treino$Peso) & 
  !is.na(dados_treino$Batimento.Cardiaco) & 
  !is.na(dados_treino$Idade),]

dados_validacao_sem_NAs <- dados_validacao[
  !is.na(dados_validacao$Duracao) & 
  !is.na(dados_validacao$Temperatura.Corporal)&
  !is.na(dados_validacao$Peso),]
paste("####################################################################")
paste("####################################################################")

# Sumário da base pós limpeza
paste("O dataframe de TREINO possui",nrow(dados_treino_sem_NAs),"registros após a limpeza",sep=" ")
paste("summary TREINO:")
summary(dados_treino_sem_NAs)
NAs_removidos_treino <- nrow(dados_treino) - nrow(dados_treino_sem_NAs)
paste("Foram removidos",NAs_removidos_treino,
      " registros inválidos do dataset de TREINO", sep=" ")
paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao_sem_NAs),"registros após a limpeza",sep=" ")
paste("####################################################################")
paste("summary VALIDAÇÃO:")
summary(dados_validacao_sem_NAs)
NAs_removidos_validacao <- nrow(dados_validacao) - nrow(dados_validacao_sem_NAs)
paste("Foram removidos",NAs_removidos_validacao,
      " registros inválidos do dataset de VALIDAÇÃO", sep=" ")
paste("####################################################################")
paste("####################################################################")

# One Hot Encoding
paste("One hot encoding para conjunto de TREINO")
dados_para_encoding_treino <- dados_treino_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, genero_one_hot_encoding)

dados_para_encoding_treino$Idade <- NULL
dados_para_encoding_treino$Genero <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

paste("One hot encoding para conjunto de VALIDAÇÃO")

dados_para_encoding_validacao <- dados_validacao_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, genero_one_hot_encoding)

dados_para_encoding_validacao$Idade <- NULL
dados_para_encoding_validacao$Genero <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))
paste("####################################################################")
paste("####################################################################")

# Normalização
dados_treino_para_normalizacao <- dados_para_encoding_treino
dados_validacao_para_normalizacao <- dados_para_encoding_validacao
min_features <- apply(dados_treino_para_normalizacao[, 1:6], 2, min)
max_features <- apply(dados_treino_para_normalizacao[, 1:6], 2, max)
diff         <- max_features - min_features

treino_normalizado <- dados_treino_para_normalizacao
validacao_normalizado <- dados_validacao_para_normalizacao

treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, min_features, "-")
treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, diff, "/")

validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, min_features, "-")
validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, diff, "/")
paste("####################################################################")

# Análise da distribuição dos dados de treino
ggplot(dados_treino_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_treino_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_treino_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_treino_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_treino_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_treino_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_treino_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

paste("#####################################################################")
paste("#####################################################################")
paste("#####################################################################")

# Distribuição dos dados de valição

ggplot(dados_validacao_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_validacao_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_validacao_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_validacao_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_validacao_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_validacao_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_validacao_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

paste("#####################################################################")
paste("#####################################################################")

# Calculando a matriz de correlação
correlation <- cor(treino_normalizado[,c(1:6, 13:14)])
print(correlation)

corrplot(correlation, method = "color", type = "upper",
         addCoef.col = "black", tl.col = "black", tl.srt = 45, number.cex = 1)


# Análise de Feature x Variável, para observar o comportamento da influência de 
# cada feature na variável alvo.
ggplot(dados_treino_sem_NAs, aes(x = Peso, y = Calorias)) + geom_point() + geom_smooth()
ggplot(dados_treino_sem_NAs, aes(x = Altura, y = Calorias)) + geom_point() + geom_smooth()
ggplot(dados_treino_sem_NAs, aes(x = Duracao, y = Calorias)) + geom_point() + geom_smooth()
ggplot(dados_treino_sem_NAs, aes(x = Batimento.Cardiaco, y = Calorias)) + geom_point() + geom_smooth()
ggplot(dados_treino_sem_NAs, aes(x = Temperatura.Corporal, y = Calorias)) + geom_point() + geom_smooth()
ggplot(dados_treino_sem_NAs, aes(x = Genero, y = Calorias)) + geom_point()
ggplot(dados_treino_sem_NAs, aes(x = Idade, y = Calorias)) + geom_point()
```


1.1 -- Quantas amostras existem no conjunto de dados? Como vocês lidarão com features categóricas, caso existam?
**Resposta:**
O dataframe de treino possui 10513 registros, já o de validação possui 2260 registros. 
Identificamos que as features Genero e Idade são categóricas. Para elas, realizamos o processo de one hot encoding, em que 
foram criadas uma coluna para cada valor discreto possível para essas features.
<!-- Fim da resposta -->

1.2 -- Existem amostras com valores ausentes? Como vocês pretendem tratar esses casos?
**Resposta:**
Desses dataframes, foram removidos os registros inválidos, após esse processo o dataframe de treino ficou com 8729 registros e o de validação com 1914 registros.
<!-- Fim da resposta -->

1.3 -- Há alguma característica dos dados que pode impactar o desempenho do modelo?
**Resposta:**
Analisando a distribuição dos dados de cada feature, notamos que Altura, Peso e Batimento Cardíaco se assemelham muito com uma gaussiana. A feature de Temperatura Corporal tem uma Assimetria positiva, ou seja, uma cauda longa à esquerda do valor da mediana dos dados. Para a feature de duração de exercícios, temos quase uma distribuição uniforme dos valores, sendo a única exceção os extremos superiores e inferiores dos dados, que possuem um valor de frequência próximo à metade dos demais. A distribuição da feature de gênero nos indica que os dois valores presentes no dataset possuem uma contagem muito próxima, não demonstrando qualquer desbalanceamento entre essas classes. Já a feature de idade mostra um decaimento na contagem de registros conforme a faixa de idade aumenta, indicando que o total de registros contidos das faixas de 20-29 e 30-39 anos é quase igual a soma das demais faixas.
Realizamos o plot da matriz de correlação das features contidas no dataset, onde observamos que as features Peso e Altura têm uma baixíssima correlação com 
a feature de Calorias, sendo um valor de 0.03 e 0.02 respectivamente. Com isso, podemos afirmar que a presença dessas features não ajudará a explicar
a variável objetivo do modelo, que é Calorias.
Por fim, plotamos scatter plots para cada feature, onde podemos ver que a relação entre Temperatura.Corporal e Batimento.Cardiaco para Calorias parece ser algo que se aproxima de **quadrático**, sugerindo oportunidades de melhoria ao tentarmos fazer uma regressão polinomial. A baixa correlação do Peso e Altura com as Calorias fica mais evidente, portanto, podemos desconsiderar estas features nas melhorias do modelo, pois não tem boa explicabilidade dos dados.

<!-- Fim da resposta -->

# Tarefa 2 -- Modelo Baseline

Treinem um modelo baseline de regressão linear utilizando **todas as features disponíveis**.

```{r atv2-code}
# Função para calcular o MAE
MAE <- function(preds, labels) {
  mae_values <- sum(abs(preds - labels)) / length(preds)
  return(mae_values)
}

# Função para calcular o MSE
MSE <- function(preds, labels) {
  mse_values <- sum((preds - labels)^2) / length(preds)
  return(mse_values)
}

# Função para calcular o MSE
RMSE <- function(preds, labels) {
  sqrt(MSE(preds, labels))
}

RAE <- function(preds, labels) {
  sum(abs(preds-labels))/sum(abs(preds-mean(labels)))
}

# Função para calcular o R²
R2 <- function(pred, true) {
  rss <- sum((pred - true)^2)
  tss <- sum((true - mean(true))^2)
  r2 <- 1 - rss / tss
  return(r2)
}

# Treinamento    
baseline <- lm(formula = Calorias ~ Peso + Altura +
               Duracao + Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 +
               Idade30_39 +
               Idade40_49 +
               Idade50_59 +
               Idade60_69 +
               Idade70_79 +
               Generofeminino +
               Generomasculino, 
               data=treino_normalizado)

# Avaliação do Modelo
model_metrics <- function(train_set, validation_set, model){
  # Realizando previsões nos dados de treino e validação
  train_pred <- predict(model, train_set)
  valid_pred <- predict(model, validation_set)
  
  # Calculando as métricas para o conjunto de treino
  mae_train <- MAE(train_pred, train_set$Calorias)
  mse_train <- MSE(train_pred, train_set$Calorias)
  rmse_train <- RMSE(train_pred, train_set$Calorias)
  rae_train <- RAE(train_pred, train_set$Calorias)
  r2_train  <- R2(train_pred, train_set$Calorias)
  
  # Calculando as métricas para o conjunto de validação
  mae_valid <- MAE(valid_pred, validation_set$Calorias)
  mse_valid <- MSE(valid_pred, validation_set$Calorias)
  rmse_valid <- RMSE(valid_pred, validation_set$Calorias)
  rae_valid <- RAE(valid_pred, validation_set$Calorias)
  r2_valid  <- R2(valid_pred, validation_set$Calorias)
  
  
  # Organizando os resultados em um dataframe
  results_baseline <- data.frame(
    Metric = c("Train", "Valid"),
    MAE = c(mae_train, mae_valid),
    MSE = c(mse_train, mse_valid),
    R2 = c(r2_train, r2_valid),
    RMSE = c(rmse_train, rmse_valid),
    RAE = c(rae_train, rae_valid)
  )
  
  # Formatando os resultados para melhor leitura
  results_baseline$MAE <- as.numeric(results_baseline$MAE)
  results_baseline$MSE <- as.numeric(results_baseline$MSE)
  results_baseline$R2 <- as.numeric(results_baseline$R2)
  results_baseline$RMSE <- as.numeric(results_baseline$RMSE)
  results_baseline$RAE <- as.numeric(results_baseline$RAE)
  
  # Exibindo os resultados
  results_baseline
}

model_metrics(treino_normalizado, validacao_normalizado, baseline)
```

2.1 -- O modelo baseline foi suficiente para resolver o problema? Quais métricas de avaliação vocês utilizaram para justificar a resposta?

**Resposta:** 
O modelo base apresentou um bom desempenho para explicar o comportamento dos dados. A métrica de erro absoluto médio atingiu 0.02647 e o coeficiente de determinação R2
atingiu valor de 0.96622 na validação, mostrando que a variância da variável Calorias é bem explicada pelas demais features do dataset.
<!-- Fim da resposta -->

# Tarefa 3 -- Combinação de Features

Implementem soluções alternativas baseadas em regressão linear através da combinação das features existentes para melhorar o resultado do *baseline*. Comparem suas soluções reportando os erros no **conjunto validação**. Vocês podem solicitar ajuda de uma LLM (Maritca AI, ChatGPT, DeepSeek, etc) se preferirem.

**Lembrem-se que as features categóricas podem ser incluída no modelo mas fora do processo de combinação**. Vejam o Ex01.R como referência.

```{r atv3-code}
# Hipóteses alternativas
f01 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           Generofeminino + 
                           Generomasculino +
                           (Batimento.Cardiaco * Temperatura.Corporal))

f02 <- formula(Calorias ~ Duracao + 
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           (Batimento.Cardiaco * Temperatura.Corporal))

f03 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           Generofeminino + 
                           Generomasculino +
                           (Batimento.Cardiaco * Duracao))

f04 <- formula(Calorias ~ Duracao +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           (Batimento.Cardiaco * Duracao))

f05 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           Generofeminino + 
                           Generomasculino +                 
                           (Duracao * Temperatura.Corporal))

f06 <- formula(Calorias ~ Batimento.Cardiaco +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           Generofeminino + 
                           Generomasculino +                 
                           (Duracao * Temperatura.Corporal))

f07 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                           (Duracao * Temperatura.Corporal * Batimento.Cardiaco))

f08 <- formula(Calorias ~  Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +                 
                           (Duracao * Temperatura.Corporal * Batimento.Cardiaco))

f09 <- formula(Calorias ~ Duracao + Batimento.Cardiaco +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                 
               (Duracao * Batimento.Cardiaco))

f10 <- formula(Calorias ~ Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                     
               (Batimento.Cardiaco * Temperatura.Corporal))

f11 <- formula(Calorias ~ Duracao + Temperatura.Corporal +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                     
               (Duracao * Temperatura.Corporal))

f12 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + 
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                     
               (Duracao * Batimento.Cardiaco * Temperatura.Corporal))

f13 <- formula(Calorias ~ Duracao + Temperatura.Corporal + 
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                     
               (Duracao * Temperatura.Corporal * Batimento.Cardiaco))

f14 <- formula(Calorias ~ Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               Generofeminino + 
               Generomasculino +                     
               (Duracao * Batimento.Cardiaco * Temperatura.Corporal))

f15 <- formula(Calorias ~ Batimento.Cardiaco + Temperatura.Corporal + Duracao +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               (Duracao + Batimento.Cardiaco + Temperatura.Corporal)^2)

f16 <- formula(Calorias ~ Duracao + Batimento.Cardiaco +
               Idade20_29 + Idade30_39 + Idade40_49 +
               Idade50_59 + Idade60_69 + Idade70_79 +
               (Duracao * Batimento.Cardiaco) +  Batimento.Cardiaco^2)

# Lista completa de fórmulas
formulas <- c(f01, f02, f03, f04, f05, f06, f07, f08,
              f09, f10, f11, f12, f13, f14, f15, f16)

MaePerCombination <- data.frame(Formula  = numeric(length(formulas)), 
                                TrainMAE = numeric(length(formulas)),
                                ValMAE   = numeric(length(formulas)))

models_combination <- list()

i <- 1
for(f in formulas){
  model <- lm(formula = f, data = treino_normalizado)
  models_combination[[i]] <- model
  
  # Previsões
  train_pred <- predict(model, treino_normalizado)
  valid_pred <- predict(model, validacao_normalizado)

  # Erros
  mae_train <- MAE(train_pred, treino_normalizado$Calorias)
  mae_val   <- MAE(valid_pred, validacao_normalizado$Calorias)

  # Resultados
  MaePerCombination[i, ] <- c(i, mae_train, mae_val)
  i <- i + 1
}

MaePerCombination[order(MaePerCombination$ValMAE),]

```

3.1 -- Quais foram os critérios utilizados para selecionar as combinações de features?

**Resposta:** 
Para desenvolver as fórmulas, partimos da conclusão que as features **Altura** e **Peso** não teriam influência na performance do modelo. Além disso, tentamos explorar combinações das variáveis Duracao, Batimento Cardiaco e Temperatura Corporal, que se mostraram altamente correlacionadas. Em algumas das fórmulas, tentamos também remover algumas das features categóricas, onde percebemos um impacto **positivo** ao remover a feature *Genero** ao tentar predizer o gasto calórico.
<!-- Fim da resposta -->


3.2 -- Alguma combinação gerou um impacto positivo ou negativo significativo no desempenho do modelo? Por quê?

**Resposta:** <!-- Escreva sua resposta abaixo -->
O modelo 8 foi o que teve a melhor performance segundo a métrica MAE, seguido de perto pelos modelos 16 e 4. Além disso, os modelos 12, 13, 14, 15, 9 e 3 tiveram performances muito próximas, mostrando que diferentes combinações lineares das features Duracao, Batimento Cardiaco e Temperatura Corporal não melhoram muito o modelo, mas são relevantes para performar acima do baseline. 
<!-- Fim da resposta -->

3.3 -- Existe alguma relação entre viés e variância no seu modelo ao modificar as combinações de features?

**Resposta:** <!-- Escreva sua resposta abaixo -->
Ao analisar o conjunto de resultados de MAE, os modelos 11 e 10 parecem apresentar um comportamento de alto viés (underfitting), evidenciado pelo MAE de validação e treino bem mais altos que o do modelo baseline. Não foi possível identificar um comportamento de variância nos modelos testados, sugerindo que todas as abordagens foram simples demais para capturar este efeito.
<!-- Fim da resposta -->

# Tarefa 4 -- Modelos Polinomiais

Implementem soluções alternativas baseadas em regressão linear aumentando os graus das features (regressão com polinômios) para melhorar o resultado obtido no baseline. Plotem o erro no conjunto de treinamento e validação pelo grau do polinômio.

```{r atv4-code}
# Hipóteses polinomiais (desconsiderando features de baixa relevancia, como vimos anteriormente)

# Desconsiderando Altura, Peso, Genero

features_numericas <- colnames(treino_normalizado)[3:5]
features_categoricas <- colnames(treino_normalizado)[7:12]

# Polinomial de grau 1
f_pol01 <- getHypothesis(features_numericas, features_categoricas, degree = 1)

# Polinomial de grau 2
f_pol02 <- getHypothesis(features_numericas, features_categoricas, degree = 2)

# Polinomial de grau 3
f_pol03 <- getHypothesis(features_numericas, features_categoricas, degree = 3)

# Polinomial de grau 4
f_pol04 <- getHypothesis(features_numericas, features_categoricas, degree = 4)

# Polinomial de grau 5
f_pol05 <- getHypothesis(features_numericas, features_categoricas, degree = 5)

# Polinomial de grau 6
f_pol06 <- getHypothesis(features_numericas, features_categoricas, degree = 6)

# Polinomial de grau 7
f_pol07 <- getHypothesis(features_numericas, features_categoricas, degree = 7)

# Polinomial de grau 8
f_pol08 <- getHypothesis(features_numericas, features_categoricas, degree = 8)

# Polinomial de grau 9
f_pol09 <- getHypothesis(features_numericas, features_categoricas, degree = 9)

# Polinomial de grau 20
f_pol20 <- getHypothesis(features_numericas, features_categoricas, degree = 20)

# Polinomial de grau 50
f_pol50 <- getHypothesis(features_numericas, features_categoricas, degree = 50)

# Lista completa de fórmulas
formulas <- c(f_pol01, f_pol02, f_pol03, f_pol04, f_pol05, f_pol06, f_pol07, f_pol08, f_pol09, f_pol20, f_pol50)

MaePerDegree <- data.frame(Formula  = numeric(length(formulas)), 
                                TrainMAE = numeric(length(formulas)),
                                ValMAE   = numeric(length(formulas)))
models_polynomial <- list()

i <- 1
for(f in formulas){
  model <- lm(formula = f, data = treino_normalizado)
  models_polynomial[[i]] <- model

  # Previsões
  train_pred <- predict(model, treino_normalizado)
  valid_pred <- predict(model, validacao_normalizado)

  # Erros
  mae_train <- MAE(train_pred, treino_normalizado$Calorias)
  mae_val   <- MAE(valid_pred, validacao_normalizado$Calorias)

  # Resultados
  MaePerDegree[i, ] <- c(i, mae_train, mae_val)
  i <- i + 1
}

MaePerDegree

MaePerDegreeMelt <- melt(MaePerDegree, id="Formula")

p <- ggplot(data=MaePerDegreeMelt, aes(x=Formula, y=value, colour=variable)) + geom_line() + geom_point()

p <- p + ggtitle("Curva vies/variancia") + ylab("MAE") + scale_x_discrete(name ="Ordem Polinomial (10 = grau 20 e 11 = grau 50)", limits=as.character(1:length(formulas)))

p + theme(legend.position = c(0.7, 0.85), legend.title = element_blank())
```

```{r}
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[1]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[2]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[3]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[7]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[9]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[10]])
model_metrics(treino_normalizado, validacao_normalizado, models_polynomial[[11]])
```

4.1 -- Como o grau do polinômio afetou o desempenho do modelo?
**Resposta:** <!-- Escreva sua resposta abaixo -->
Analisando a curva Vies/Variância do MAE, percebemos que existe uma queda inicial brusca do grau 1 para o grau 2, onde o modelo mostra uma melhora significativa. A partir deste ponto, o MAE de treino permanece estável e o MAE de validação só aumenta gradativamente, em direção ao MAE de treino. Conforme o grau aumenta, o erro de validação tende a crescer lentamentamente, conforme o modelo se aproxima do overfitting. Um comportamento curioso é o fato do erro de validação estar sendo geralmente menor que o erro de treinamento.
<!-- Fim da resposta -->

4.2 -- Houve um ponto ótimo onde o erro foi minimizado? Como vocês identificaram esse ponto?

**Resposta:** <!-- Escreva sua resposta abaixo -->
O erro é minimizado com o modelo polinomial de grau 2, como pode ser observado no gráfico, que tem um ponto de mínimo no grau 2 com MAE_validacao = 0.02015. No grau 1, o modelo ainda está muito simples e, ao evoluir para o grau 2, conseguimos observar uma queda no erro que se mantem estável para todos os outros graus acima, chegando a piorar na validação para graus muito mais altos.
<!-- Fim da resposta -->

4.3 -- Em quais regiões da curva de viés e variância foi possível identificar underfitting e overfitting?

**Resposta:** <!-- Escreva sua resposta abaixo -->
Para o grau 1, o modelo mostra underfitting, pois o erro de treinamento e de validação estão altos. Para todos os outros graus acima, até o grau 8, o comportamento do modelo permanece relativamente estável, com erro de treino ligeiramente abaixo do erro de validação, até que para os graus 20 e 50 (exemplos extrapolados), o erro de validação aumenta bastante acima do erro de treino, indicando overfitting.
<!-- Fim da resposta -->

# Tarefa 5 -- Conjunto de Teste

Após identificar o melhor modelo, utilizem-no para fazer previsões no conjunto de teste e avaliem o seu desempenho.

Regressão polinomial para o modelo com as features combinadas, usando como referencia a feature combinada f03:

```{r}
# f03 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
#                            Idade20_29 + Idade30_39 + Idade40_49 +
#                            Idade50_59 + Idade60_69 + Idade70_79 +
#                            Generofeminino + 
#                            Generomasculino +
#                            (Batimento.Cardiaco * Duracao))


f03_1 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                           Idade20_29 + Idade30_39 + Idade40_49 +
                           Idade50_59 + Idade60_69 + Idade70_79 +
                           Generofeminino + 
                           Generomasculino +
                           (Batimento.Cardiaco * Duracao))

# Grau 2
f03_2 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                I(Duracao^2) + I(Batimento.Cardiaco^2) + I(Temperatura.Corporal^2) +
                Idade20_29 + Idade30_39 + Idade40_49 +
                Idade50_59 + Idade60_69 + Idade70_79 +
                Generofeminino + Generomasculino +
                (Batimento.Cardiaco * Duracao) + 
                I(Batimento.Cardiaco * Duracao)^2)

# Grau 3
f03_3 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                I(Duracao^2) + I(Batimento.Cardiaco^2) + I(Temperatura.Corporal^2) +
                I(Duracao^3) + I(Batimento.Cardiaco^3) + I(Temperatura.Corporal^3) +
                Idade20_29 + Idade30_39 + Idade40_49 +
                Idade50_59 + Idade60_69 + Idade70_79 +
                Generofeminino + Generomasculino +
                (Batimento.Cardiaco * Duracao)+ 
                I(Batimento.Cardiaco * Duracao)^2+ 
                I(Batimento.Cardiaco * Duracao)^3)

# Grau 4
f03_4 <- formula(Calorias ~ Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                I(Duracao^2) + I(Batimento.Cardiaco^2) + I(Temperatura.Corporal^2) +
                I(Duracao^3) + I(Batimento.Cardiaco^3) + I(Temperatura.Corporal^3) +
                I(Duracao^4) + I(Batimento.Cardiaco^4) + I(Temperatura.Corporal^4) +
                Idade20_29 + Idade30_39 + Idade40_49 +
                Idade50_59 + Idade60_69 + Idade70_79 +
                Generofeminino + Generomasculino +
                (Batimento.Cardiaco * Duracao) +
                I(Batimento.Cardiaco * Duracao)^2+ 
                I(Batimento.Cardiaco * Duracao)^3+ 
                I(Batimento.Cardiaco * Duracao)^4)

# Lista completa de fórmulas
formulas <- c(f03_1, f03_2, f03_3, f03_4)

MaePerDegreeForBetterCombination <- data.frame(Formula  = numeric(length(formulas)), 
                                TrainMAE = numeric(length(formulas)),
                                ValMAE   = numeric(length(formulas)))

i <- 1
for(f in formulas){
  model <- lm(formula = f, data = treino_normalizado)

  # Previsões
  train_pred <- predict(model, treino_normalizado)
  valid_pred <- predict(model, validacao_normalizado)

  # Erros
  mae_train <- MAE(train_pred, treino_normalizado$Calorias)
  mae_val   <- MAE(valid_pred, validacao_normalizado$Calorias)

  # Resultados
  MaePerDegreeForBetterCombination[i, ] <- c(i, mae_train, mae_val)
  i <- i + 1
}

MaePerDegreeForBetterCombination
```



## Avaliação do melhor modelo:

```{r}
min(MaePerCombination$ValMAE)
min(MaePerDegree$ValMAE)
min(MaePerDegreeForBetterCombination$ValMAE)
```
O Modelo com melhor desempenho, usando como referência o Erro Médio Absoluto, foi o polinomial de grau 2 sem combinação entre features.


## Avaliando modelo no conjunto de teste:

```{r}
dados_teste <- read.csv("T01_test_set.csv")

paste("O dataframe de TESTE possui",nrow(dados_teste),"registros",sep=" ")
paste("###################################################################")
paste("summary TESTE:")
summary(dados_teste)
```

Analisando o conjunto de teste notamos que não possuem registros inválidos, ou seja, com valores NA.

```{r}
paste("#####################################################")
paste("One hot encoding para conjunto de TREINO")
dados_para_encoding_teste <- dados_teste
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_teste)
dados_para_encoding_teste <- cbind(dados_para_encoding_teste, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_teste)
dados_para_encoding_teste <- cbind(dados_para_encoding_teste, genero_one_hot_encoding)

dados_para_encoding_teste$Idade <- NULL
dados_para_encoding_teste$Genero <- NULL
colnames(dados_para_encoding_teste) <- gsub("-", "_", colnames(dados_para_encoding_teste))

test_normalized <- dados_para_encoding_teste

test_normalized[,1:6]  <- sweep(test_normalized[,1:6], 2, min_features, "-")
test_normalized[,1:6]  <- sweep(test_normalized[,1:6], 2, diff, "/")

test_normalized[, 1:6] <- as.data.frame(lapply(test_normalized[, 1:8], function(x) pmax(0, pmin(1, x))))

head(test_normalized)
```


```{r atv5-code}

best_model <- lm(formula=Calorias ~ Altura + Peso + Duracao + Batimento.Cardiaco + 
                 Temperatura.Corporal +
                 I(Altura^2) + I(Peso^2) + I(Duracao^2) + I(Batimento.Cardiaco^2) +
                 I(Temperatura.Corporal^2) +
                 Idade20_29 + Idade30_39 + Idade40_49 + Idade50_59 +
                 Idade60_69 + Idade70_79 + Generofeminino + Generomasculino, data=treino_normalizado)


test_pred <- predict(best_model, test_normalized)

mae_test <- MAE(test_pred, test_normalized$Calorias)
mse_test <- MSE(test_pred, test_normalized$Calorias)
r2_test  <- R2(test_pred,  test_normalized$Calorias)

results_cat <- data.frame(
  Metric = c("MAE", "MSE", "R2"),
  Test = c(mae_test, mse_test, r2_test)
)

results_cat$Test <- as.numeric(results_cat$Test)
results_cat$Test <- format(results_cat$Test, scientific = FALSE)

results_cat
```


5.1 -- Qual foi o critério adotado para definir o melhor modelo?

5.2 -- Como os resultados no conjunto de teste se comparam aos obtidos no conjunto de validação? Houve algum indício degradação ou melhora do modelo?

5.3 -- Expliquem a diferença entre os modelos e o porquê que estas diferenças levaram a resultados piores ou melhores.

5.4 -- Considerando as diferentes abordagens testadas, quais estratégias poderiam ser aplicadas para melhorar ainda mais o desempenho do modelo?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Observações Finais

Justifiquem suas escolhas com base em evidências (métricas, gráficos, hipóteses teóricas).

A clareza na comunicação dos resultados é mais importante do que a qualidade do modelo!
