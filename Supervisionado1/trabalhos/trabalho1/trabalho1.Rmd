---
title: INF0615 -- Aprendizado Supervisionado I
output: pdf_document
subtitle: Trabalho 1 - Predição de Calorias Queimadas
author: 
  - Vitor de Oliveira Fernandez Araujo
  - Vitor Sancho Cardoso
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo = TRUE,      # Exibir código nos chunks
  error = FALSE,    # Ocultar mensagens de erro
  message = FALSE,  # Ocultar mensagens informativas
  warning = FALSE,  # Ocultar avisos
  tidy = FALSE      # Não reformatar automaticamente o código
)

options(digits = 3) # Definição do número de casas decimais padrão
```

## 01 - Análise exploratória dos dados

Inicialmente é necessário fazer a importação do conjunto de dados que será utilizado no treino do nosso modelo de regressão:

```{r}
dados_treino <- read.csv("T01_train_set.csv")
dados_validacao <- read.csv("T01_valid_set.csv")

paste("O dataframe de TREINO possui",nrow(dados_treino),"registros",sep=" ")
paste("###################################################################")
paste("summary TREINO:")
summary(dados_treino)
paste("###################################################################")
paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao),"registros",sep=" ")
paste("###################################################################")
paste("summary VALIDAÇÃO:")
summary(dados_validacao)


paste("###################################################################")
```
Ao executar o summary é possível identificar que o conjunto de dados é composto por registros associados à prática de atividade física para uma pessoa. Os registros contêm dados sobre características da pessoa e indicadores da atividade física realizada. Cada registro possui 7 features: Gênero, Altura, Peso, Duração do exercício, Batimento Cardíaco, Temperatura Corporal e Idade. Por fim, cada registro possui seu valor de Calorias consumidas. Essa última coluna será utilizada como ground truth de nosso conjunto de dados.

Além disso, o summary nos indica a presença de itens inválidos no conjunto de dados. Esses são determinados a partir da presença de NA em uma ou mais features do registro. Esses valores são removidos abaixo:

```{r}
dados_treino_sem_NAs <- dados_treino[!is.na(dados_treino$Genero) & !is.na(dados_treino$Altura) & !is.na(dados_treino$Peso) & !is.na(dados_treino$Batimento.Cardiaco) & !is.na(dados_treino$Idade),]


paste("###################################################################")
paste("summary após a remoção de regitros com NA:")
summary(dados_treino_sem_NAs)

paste("###################################################################")
paste("Foram removidos",nrow(dados_treino) - nrow(dados_treino_sem_NAs)," registros inválidos", sep=" ")

paste("Versão final após limpeza dos dados possui",nrow(dados_treino_sem_NAs),"registros",sep=" ")

paste("###################################################################")

dados_validacao_sem_NAs <- dados_validacao[!is.na(dados_validacao$Duracao) & !is.na(dados_validacao$Temperatura.Corporal)& !is.na(dados_validacao$Peso),]


paste("###################################################################")
paste("summary após a remoção de regitros com NA:")
summary(dados_validacao_sem_NAs)

paste("###################################################################")
paste("Foram removidos",nrow(dados_validacao) - nrow(dados_validacao_sem_NAs)," registros inválidos do dataset de VALIDAÇÃO", sep=" ")

paste("Versão final após limpeza dos dados possui",nrow(dados_validacao_sem_NAs),"registros",sep=" ")
paste("###################################################################")
```

Um outro ponto a se analisar é a distribuição de cada uma das features. É importante observar isso pois, caso existam features com valores muito desbalanceados, isso pode interferir na performance do modelo treinado. Além disso, essa observação nos permite realizar correções no modelo de forma a balancear esses valores.
A distribuição de cada uma das features pode ser vista abaixo:

```{r}
library(ggplot2)

# Histograma da altura
ggplot(dados_treino_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_treino_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_treino_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_treino_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_treino_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_treino_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_treino_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

```

É possível notar que a distribuição das features de altura, peso e batimento cardíaco se assemelham muito com uma gaussiana. A de temperatura corporal é uma gaussiana com Assimetria positiva, ou seja, com uma cauda longa à esquerda do valor da mediana dos dados. Para a feature de duração de exercícios temos quase uma distribuição uniforme dos valores, sendo a única exceção os extremos superiores e inferiores dos dados, que possuem um valor de frequência prómixo a metade dos demais. A distribuição da feature de gênero nos indica que os dois valores presenter no dataset possuem uma contagem muito próxima, não demonstrando qualquer desbalanceamento entre essas classes. Já a feature de idade mostra um decaimento na contagem de registros conforme a faixa de idade aumenta, indicando que o total de registros contidos das faixas de 20-29 e 30-39 anos é quase igual a soma das demais faixas.

Abaixo podemos ver os mesmos gráficos para o conjunto de validação. É possível notar o mesmo comportamento para cada feature já analisada acima.

```{r}
library(ggplot2)

# Histograma da altura
ggplot(dados_validacao_sem_NAs, aes(x = Altura)) +
  geom_histogram(binwidth = 5, fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da altura", x = "Altura (cm)", y = "Frequência")

# Histograma do peso
ggplot(dados_validacao_sem_NAs, aes(x = Peso)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do peso", x = "Peso (kg)", y = "Densidade")

# Histograma do duração do exercício
ggplot(dados_validacao_sem_NAs, aes(x = Duracao)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do duração do exercício", x = "Duração", y = "Densidade")

# Histograma do batimetno cardiaco
ggplot(dados_validacao_sem_NAs, aes(x = Batimento.Cardiaco)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do batimento cardiaco", x = "Duração", y = "Densidade")

# Histograma da temperatura corporal
ggplot(dados_validacao_sem_NAs, aes(x = Temperatura.Corporal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição da temperatura corporal", x = "Duração", y = "Densidade")

ggplot(dados_validacao_sem_NAs, aes(x = Genero, fill = Genero)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Gênero", x = "Gênero", y = "Contagem")

ggplot(dados_validacao_sem_NAs, aes(x = Idade, fill = Idade)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Faixa Etária", x = "Idade", y = "Contagem")

```
Ao observar o conjunto de dados e as distribuições plotadas acima nos chama atenção o tipo de dado das features Idade e Gênero.
Podemos ver uma amostra destas abaixo:

```{r}
paste("Amostra de dados de idade:")
head(dados_treino_sem_NAs$Idade)
paste("###################################################################")
paste("Amostra de dados de genero:")
head(dados_treino_sem_NAs$Genero)
paste("###################################################################")
```
Como podemos ver acima, essas features possuem valores discretos, sendo classificadas como features categóricas. 
Dado essa característica será necessário alterar os valores para essas features de forma que tenham valores numéricos.
Esse processo é denominado one-hot-encoding e é executado abaixo para as features categóricas do dataset.


```{r}
paste("#####################################################")
paste("One hot encoding para conjunto de TREINO")
dados_para_encoding_treino <- dados_treino_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, genero_one_hot_encoding)

dados_para_encoding_treino$Idade <- NULL
dados_para_encoding_treino$Genero <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

paste("#####################################################")
paste("One hot encoding para conjunto de VALIDAÇÃO")

dados_para_encoding_validacao <- dados_validacao_sem_NAs
idade_one_hot_encoding <- model.matrix(~Idade - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, idade_one_hot_encoding)

genero_one_hot_encoding <- model.matrix(~Genero - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, genero_one_hot_encoding)

dados_para_encoding_validacao$Idade <- NULL
dados_para_encoding_validacao$Genero <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))

paste("#####################################################")
paste("Amostra dos dados de TREINO")
head(dados_para_encoding_treino, 20)
paste("Amostra dos dados de VALIDAÇÃO")
head(dados_para_encoding_validacao, 20)
```

Foi realizado um ajuste de forma que, para cada valor que as features categóricas podem assumir, foi criada uma feature a mais no dataset. Essas colunas podem assumir o valor 1 quando o registro assume o valor da respectiva categoria, ou 0 quando não assumem o valor da nova feature. Após essas análises e ajustes podemos prosseguir para o treinamento do modelo baseline. 

## 02 - Normalização das features

Para o treinamento do modelo baseline iremos aplicar a normalização Min-Max. A normalização será aplicada somente para as 6 primeiras colunas dos datasets de treino e de validação, as demais features foram geradas no one hot encoding e somente podem assumir os valores 0 ou 1.

```{r}
# Calculando os valores mínimos e máximos de cada variável
min_features <- apply(dados_para_encoding_treino[, 1:6], 2, min)
max_features <- apply(dados_para_encoding_treino[, 1:6], 2, max)
diff         <- max_features - min_features

print("Valores mínimos")
print(min_features)
print("Valores máximos")
print(max_features)
print("Diferença entre máximos e mínimos")
print(diff)
```

```{r}
# Aplicando a normalização Min-Max nos dados de treino e validação
treino_normalizado <- dados_para_encoding_treino
validacao_normalizado <- dados_para_encoding_validacao

treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, min_features, "-")
treino_normalizado[, 1:6] <- sweep(treino_normalizado[, 1:6], 2, diff, "/")

validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, min_features, "-")
validacao_normalizado[, 1:6] <- sweep(validacao_normalizado[, 1:6], 2, diff, "/")

```

Ao visualizar o resultado da normalização aplicada, esperamos que os valores das colunas normalizadas estejam compreendidos entre 0 e 1. É, também, importante notar o uso das informações de máximo e mínimo extraídos do **conjunto de treino**,  para realizar a normalização do conjunto de validação.
```{r}

summary(treino_normalizado[,1:6])
summary(validacao_normalizado[,1:6])

```


Agora que já fizemos todos o tratamento dos dados, passando pela remoção de registros inválidos até a normalização, utilizando o método de Min-Max, podemos iniciar o treinamento do modelo.

## 03 - Treinamento de modelo baseline


```{r}
# Treinando o modelo de regressão linear com as variáveis contínuas
baseline <- lm(formula = Calorias ~ Altura + Peso
               + Duracao + Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 +
                 Idade30_39 +
                 Idade40_49 +
                 Idade50_59 +
                  Idade60_69 +
                 Idade70_79 +
                 Generofeminino + 
                 Generomasculino
               ,data=treino_normalizado)

# Exibindo o resumo do modelo ajustado
summary(baseline)
```
```{r}
# Função para calcular o MAE
MAE <- function(preds, labels) {
  mae_values <- sum(abs(preds - labels)) / length(preds)
  return(mae_values)
}

# Função para calcular o MSE
MSE <- function(preds, labels) {
  mse_values <- sum((preds - labels)^2) / length(preds)
  return(mse_values)
}

# Função para calcular o R²
R2 <- function(pred, true) {
  rss <- sum((pred - true)^2)
  tss <- sum((true - mean(true))^2)
  r2 <- 1 - rss / tss
  return(r2)
}
```




```{r}

model_metrics <- function(train_set, validation_set, model){
  # Realizando previsões nos dados de treino e validação
  train_pred <- predict(model, train_set)
  valid_pred <- predict(model, validation_set)
  
  # Calculando as métricas para o conjunto de treino
  mae_train <- MAE(train_pred, train_set$Calorias)
  mse_train <- MSE(train_pred, train_set$Calorias)
  r2_train  <- R2(train_pred, train_set$Calorias)
  
  # Calculando as métricas para o conjunto de validação
  mae_valid <- MAE(valid_pred, validation_set$Calorias)
  mse_valid <- MSE(valid_pred, validation_set$Calorias)
  r2_valid  <- R2(valid_pred, validation_set$Calorias)
  
  
  # Organizando os resultados em um dataframe
  results_baseline <- data.frame(
    Metric = c("MAE", "MSE", "R2"),
    Train = c(mae_train, mse_train, r2_train),
    Valid = c(mae_valid, mse_valid, r2_valid)
  )
  
  # Formatando os resultados para melhor leitura
  results_baseline$Train <- as.numeric(results_baseline$Train)
  results_baseline$Valid <- as.numeric(results_baseline$Valid)
  
  # Evitando notação científica na exibição dos resultados
  results_baseline$Train <- format(results_baseline$Train, scientific = FALSE)
  results_baseline$Valid <- format(results_baseline$Valid, scientific = FALSE)
  
  # Exibindo os resultados
  results_baseline
}

model_metrics(treino_normalizado, validacao_normalizado, baseline)
```

Com base nas métricas de avaliação do modelo, podemos ver que capturamos cerca de 96% da variabilidade do dos dados com o modelo, e o comportamento dos erros foi estável (MSE baixo, significando erros pequenos, em média). Nas próximas seções, iremos estudar como utilizar as features presentes de forma a tentar melhorar estas métricas.


## 03.1 Mudando a normalização aplicada 

testando normalização de features usando z-score

```{r}
# Calculando a média e o desvio padrão para normalização
treino_normalizado_z_score <- dados_para_encoding_treino
validacao_normalizado_z_score <- dados_para_encoding_validacao

mean_features <- apply(treino_normalizado_z_score[, 1:6], 2, mean)
sd_features   <- apply(treino_normalizado_z_score[, 1:6], 2, sd)

print("Médias das features")
print(mean_features)
print("Desvios padrão das features")
print(sd_features)
```

```{r}
# Aplicando a normalização Z-Score nos dados de treino
treino_normalizado_z_score[, 1:8] <- sweep(treino_normalizado_z_score[, 1:8], 2, mean_features, "-")
treino_normalizado_z_score[, 1:8] <- sweep(treino_normalizado_z_score[, 1:8], 2, sd_features, "/")

validacao_normalizado_z_score[, 1:8] <- sweep(validacao_normalizado_z_score[, 1:8], 2, mean_features, "-")
validacao_normalizado_z_score[, 1:8] <- sweep(validacao_normalizado_z_score[, 1:8], 2, sd_features, "/")

summary(treino_normalizado_z_score)
summary(validacao_normalizado_z_score)
```



```{r}
# Treinando o modelo de regressão linear com as variáveis contínuas
baseline_z_score <- lm(formula = Calorias ~ Altura + Peso
               + Duracao + Batimento.Cardiaco + Temperatura.Corporal +
               Idade20_29 +
                 Idade30_39 +
                 Idade40_49 +
                 Idade50_59 +
                  Idade60_69 +
                 Idade70_79 +
                 Generofeminino + 
                 Generomasculino
               ,data=treino_normalizado_z_score)

# Exibindo o resumo do modelo ajustado
summary(baseline_z_score)

model_metrics(treino_normalizado_z_score, validacao_normalizado_z_score, baseline_z_score)
```


## 04 Combinando as features

Para melhorar o desempenho do modelo podemos realizar um estudo de correlação entre as features do dataset.
Abaixo é possível observar o heatmap de correlação entre as features do data set.

```{r}
# install.packages("corrplot")
library(corrplot)
# Visualizando a matriz de correlação com um heatmap
# par(mar = c(2, 2, 2, 2))  # Ajusta as margens do gráfico
# par(cex = 1.2)            # Ajusta o tamanho do texto

# dev.new(width = 15, height = 15, unit = "in", noRStudioGD = TRUE)

# Calculando a matriz de correlação
correlation <- cor(treino_normalizado[,c(1:6, 13:14)])
print(correlation)

corrplot(correlation, method = "color", type = "upper",
         addCoef.col = "black", tl.col = "black", tl.srt = 45, number.cex = 1)
```
No plot acima, é possível notar que mais features podem ser combinadas, pois possuem uma correlação elevada. As features Duração e Temperatura.Corporal tem um grau de correlação de 0.90. O valor de correlação de 0.85 é observado entre Duração e Batimento.Cardiaco, e 0.77 entre Batimento.Cardiaco e Temperatura.Corporal. Essas três são grande candidatas a serem combinadas numa só, além de ser possível combinar um par delas em somente uma. Em especial, as features Peso e Altura também tem uma correlação muito alta (0.96).

Para abordar a alta correlação entre Peso e Altura e simplificar o modelo, iremos transformar as features Peso e Altura em uma, calculando o IMC, conforme a fórmula:
$$IMC = \frac{Peso}{Altura^2}$$


```{r}
treino_engineered <- treino_normalizado
validacao_engineered <- validacao_normalizado

IMC <- function(peso, altura){
  peso/altura^2
}

treino_engineered$IMC <- IMC(dados_para_encoding_treino$Peso, dados_para_encoding_treino$Altura/100)
min_imc <- min(treino_engineered$IMC)
max_imc <- max(treino_engineered$IMC)
diff_imc <- max_imc - min_imc
treino_engineered$IMC <- (treino_engineered$IMC - min_imc)/diff_imc

treino_engineered$Peso <- NULL
treino_engineered$Altura <- NULL

validacao_engineered$IMC <- IMC(dados_para_encoding_validacao$Peso, dados_para_encoding_validacao$Altura/100)
validacao_engineered$IMC <- (validacao_engineered$IMC - min_imc)/diff_imc

validacao_engineered$Peso <- NULL
validacao_engineered$Altura <- NULL


IMC_engineered_model <- lm(formula = Calorias ~ IMC
               + Duracao + Batimento.Cardiaco + Temperatura.Corporal +
                Idade20_29 +
                Idade30_39 +
                Idade40_49 +
                Idade50_59 +
                Idade60_69 +
                Idade70_79 +
                Generofeminino + 
                Generomasculino
               ,data=treino_engineered)

model_metrics(treino_engineered, validacao_engineered, IMC_engineered_model)
model_metrics(treino_normalizado, validacao_normalizado, baseline)


```

Vimos que a substituição do IMC piorou levemente o modelo.

Além das análises de correlação, dado o número restrito de features, podemos também construir scatter plots de cada feature com a variável alvo, para observar relações não lineares que possamos incluir no modelo.
```{r}
ggplot(treino_engineered, aes(x = IMC, y = Calorias)) + geom_point() + geom_smooth()
ggplot(treino_engineered, aes(x = Duracao, y = Calorias)) + geom_point() + geom_smooth()
ggplot(treino_engineered, aes(x = Batimento.Cardiaco, y = Calorias)) + geom_point() + geom_smooth()
ggplot(treino_engineered, aes(x = Temperatura.Corporal, y = Calorias)) + geom_point() + geom_smooth()
```
Analisando os scatter plots, podemos ver que a relação entre Temperatura.Corporal e Batimento.Cardiaco para Calorias parece ser algo que se aproxima de **quadrático**, sugerindo oportunidades de melhoria ao tentarmos fazer uma regressão polinomial. A baixa correlação do IMC (e, consequentemente, peso e altura) com as Calorias fica mais evidente, portanto, podemos remover esta feature do modelo daqui para frente, pois não tem boa explicabilidade dos dados.
