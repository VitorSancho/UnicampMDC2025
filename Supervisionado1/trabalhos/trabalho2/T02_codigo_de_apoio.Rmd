---
title: INF0615 -- Aprendizado de Máquina Supervisionado I
output: pdf_document
subtitle: Trabalho 2 - Risco de Hipertensão
author: 
  - Vitor de Oliveira Fernandez Araujo
  - Vitor Sancho Cardoso
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo    = TRUE,   # Exibir código nos chunks
  error   = FALSE,  # Ocultar mensagens de erro
  message = FALSE,  # Ocultar mensagens informativas
  warning = FALSE,  # Ocultar avisos
  tidy    = FALSE   # Não reformatar automaticamente o código
)

options(digits = 4) # Definição do número de casas decimais padrão
```

Neste segundo trabalho, exploraremos a predição de risco de hipertensão utilizando regressão logística, árvore de decisão e floresta aleatória.

O conjunto de dados está disponível na página da disciplina no Moodle (arquivo `T02_SPLIT_set.csv`).

# Função de apoio

## getHypothesis

Essa função auxilia na escrita dos modelos polinomiais.

Parâmetros:

\- `X_features_names`: conjunto de *features* a serem consideradas na criação do modelo polinomial;

\- `target`: nome da coluna variável alvo do conjunto de dados;

\- `degree`: indica até qual grau polinomial as *features* serão elevadas.

```{r}
# A funcao abaixo auxilia na escrita dos modelos polinomiais. 
# Parametros:
# "real_feature_names": conjunto de features continuas que sera considerado na
#                        criacao do modelo polinomial.
#
# "categorical_feature_names": conjunto de features categoricas que sera 
#                               considerado na  criacao do modelo polinomial. Se
#                                voces desejarem um modelo sem variaveis categoricas
#                               basta nao passar nenhum valor para este parametro
#                               na chamada da funcao
# "target": nome da variável target de interesse
# "degree": numero inteiro que indica ate qual grau polinomial as features continuas
#           em "real_feature_names" serao elevadas. 
#
# A funcao retorna a hipotese ja definida para realizar o treinamento do modelo. 
# Uma ilustracao de uma funcao similar aparece no Ex02.R na linha 490

getHypothesis <- function(real_feature_names, categorical_feature_names=F, target="Has_Hypertension", degree=3){
    
    hypothesis_string <- paste("hypothesis <- formula(", target, " ~ ")
    for(d in 1:degree){
        for(i in 1:length(real_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       "I(", real_feature_names[i], "^", d, ") + ",
                                       sep = "")
        }
    }
    
    if(typeof(categorical_feature_names) != "logical"){
        for(i in 1:length(categorical_feature_names)){
            hypothesis_string <- paste(hypothesis_string, 
                                       categorical_feature_names[i], " + ",
                                       sep = "")
        } 
    }
    
    
    hypothesis_string <- substr(hypothesis_string, 1, nchar(hypothesis_string)-3)
    hypothesis_string <- paste(hypothesis_string, ")")
    hypothesis <- eval(parse(text=hypothesis_string))
    return(hypothesis)
}
```

## getLoss

Função que calcula a *Cross Entropy Loss*. Ela é útil para mostrar em gráficos de curva de viés e variância o erro de classificadores.

Parâmetros:

\- `y_true`: vetor das classes verdadeiras (*ground truth*);

\- `y_pred`: vetor das classes preditas pelo classificador.

```{r}
getLoss <- function(y_true, y_pred){
  y_pred_n <- y_pred[y_true == 0]
  y_pred_p <- y_pred[y_true == 1]
  
  countN <- length(y_pred_n)
  countP <- length(y_pred_p)
  
  eps <- 1e-9  # Constante pequena para estabilidade numérica

  totalLossN <- sum(-log2(1 - y_pred_n + eps))
  
  totalLossP <- sum(-log2(y_pred_p + eps))
  
  avgLossN <- totalLossN / countN
  avgLossP <- totalLossP / countP

  avgLossTotal <- (avgLossN + avgLossP) / 2

  return(c(LossN = avgLossN, LossP = avgLossP, AverageLoss = avgLossTotal))
}
```

## getRelativeConfusionMatrix

Função que calcula a matriz de confusão relativa.

Paramêtro:

\- `cm`: matriz de confusão absoluta.

```{r}
getRelativeConfusionMatrix <- function(cm){
    cm_absolute = t(cm$table)
    
    cm_relative = cm_absolute
    
    cm_relative[1,1] = cm_absolute[1,1]/sum(cm_absolute[1,])
    cm_relative[1,2] = cm_absolute[1,2]/sum(cm_absolute[1,])
    cm_relative[2,1] = cm_absolute[2,1]/sum(cm_absolute[2,])
    cm_relative[2,2] = cm_absolute[2,2]/sum(cm_absolute[2,])
    
    return(cm_relative)  
}
```

## getMetrics

Função que calcula diversas métricas de avaliação a partir de uma matriz de confusão.

Parâmtro:

\- `cm`: matriz de confusão (cm\$table).

```{r}
calculateMetrics <- function(cm) {
  # Extrai TN, FP, FN, TP da matriz de confusão
  cm <- t(cm)
  
  # Assumindo a estrutura:
  #           Prediction
  # Reference   0     1
  #         0   TN    FP
  #         1   FN    TP
  
  TN <- cm[1, 1]
  FP <- cm[1, 2]
  FN <- cm[2, 1]  
  TP <- cm[2, 2]  
  
  precision <- if (TP + FP == 0) 0 else TP / (TP + FP)
  recall    <- if (TP + FN == 0) 0 else TP / (TP + FN)
  f1        <- if (precision + recall == 0) 0 else (2 * precision * recall) / (precision + recall)
  bal_acc   <- ( (TN / (TN + FP)) + (TP / (TP + FN)) ) / 2
  
  return(c(Precision = precision, Recall = recall, F1 = f1, BalAcc = bal_acc))
}

## Exemplo de uso
# cm <- confusionMatrix(data = as.factor(valPred), reference = as.factor(ValSet$target), positive='1')
# metrics <- calculateMetrics(cm$table)
```

# Tarefa 0 -- Configurando o ambiente

Carregue as bibliotecas necessárias e defina uma semente aleatória para garantir a reprodutibilidade dos experimentos.

```{r atv0-code}
# Adicione as bibliotecas necessárias
#library(...)
library(ggplot2)
# install.packages("glmnet")
library(glmnet)
library(caret)
#set.seed(...)
```

# Tarefa 1 -- Inspeção de Dados

Carreguem e inspecionem o conjunto de dados. Além disso, preparem os dados corretamente para serem utilizados nos classificadores, preocupando-se com o balanceamento de classes (se necessário) e normalização (se necessário).

```{r atv1-code}
# Carregue o conjunto de dados
dados_treino <- read.csv("T02_train_set.csv")
dados_validacao <- read.csv("T02_valid_set.csv")

# Sumário da base
paste("O dataframe de TREINO possui",nrow(dados_treino),"registros",sep=" ")
paste("summary TREINO:")
summary(dados_treino)

if (any(is.na(dados_treino))) {
  cat("Aviso: Existem valores ausentes no conjunto de validação.\n")
} else {
  cat("Nenhum valor ausente encontrado no conjunto de validação.\n")
}

paste("O dataframe de VALIDAÇÃO possui",nrow(dados_validacao),"registros",sep=" ")
paste("summary VALIDAÇÃO:")
summary(dados_validacao)

if (any(is.na(dados_validacao))) {
  cat("Aviso: Existem valores ausentes no conjunto de validação.\n")
} else {
  cat("Nenhum valor ausente encontrado no conjunto de validação.\n")
}

# Avaliando dados presentes no data set
# class(dados_treino$Consumo.Sal)
# class(dados_treino$Nivel.de.Estresse)
# class(dados_treino$Historico.Pressao.Arterial)
# class(dados_treino$IMC)
# class(dados_treino$Historico.Familiar)
# class(dados_treino$Nivel.Exercicio)
# class(dados_treino$Fumante)
# class(dados_treino$Risco.Hipertensao)
# 
# head(dados_treino)
# 
# head(dados_validacao)
# 
# class(dados_validacao$Consumo.Sal)
# class(dados_validacao$Nivel.de.Estresse)
# class(dados_validacao$Historico.Pressao.Arterial)
# class(dados_validacao$IMC)
# class(dados_validacao$Historico.Familiar)
# class(dados_validacao$Nivel.Exercicio)
# class(dados_validacao$Fumante)
# class(dados_validacao$Risco.Hipertensao)
# 
# head(dados_validacao)


# Normalização
# Aplicando normalização min-max
treino_normalizado <- dados_treino
validacao_normalizado <- dados_validacao
cols <- c(1, 4, 5)  # índices das colunas numericas que vamos normalizar

min_features <- apply(treino_normalizado[, cols], 2, min)
max_features <- apply(treino_normalizado[, cols], 2, max)
diff         <- max_features - min_features

treino_normalizado[, cols] <- sweep(treino_normalizado[, cols], 2, min_features, "-")
treino_normalizado[, cols] <- sweep(treino_normalizado[, cols], 2, diff, "/")

validacao_normalizado[, cols] <- sweep(validacao_normalizado[, cols], 2, min_features, "-")
validacao_normalizado[, cols] <- sweep(validacao_normalizado[, cols], 2, diff, "/")

summary(validacao_normalizado)

```


Análise da distribuição dos dados de treino

```{r}
# Histograma do Consumo de Sal normalizado
ggplot(treino_normalizado, aes(x = Consumo.Sal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do Consumo de Sal",
       x = "Consumo de Sal normalizado", y = "Densidade")

# Histograma da Duracao de Sono normalizad
ggplot(treino_normalizado, aes(x = Duracao.Sono)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do Duracao Sono", x = "Duracao de Sono normalizada", y = "Densidade")

# Histograma do duração do IMC normalizado
ggplot(treino_normalizado, aes(x = IMC)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do IMC",
       x = "IMC normalizado", y = "Densidade")

# Contagem de ocorrencias por Nivel de Estresse
ggplot(treino_normalizado, aes(x = Nivel.de.Estresse, fill = Nivel.de.Estresse)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Nivel de Estresse", x = "Nivel de Estresse", y = "Contagem")

# Contagem de ocorrencias por Historico de Pressao Arterial
ggplot(treino_normalizado, aes(x = Historico.Pressao.Arterial, fill = Historico.Pressao.Arterial)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Historico de Pressao Arterial", x = "Historico de Pressao Arterial", y = "Contagem")

# Contagem de ocorrencias por Historico Familiar
ggplot(treino_normalizado, aes(x = Historico.Familiar, fill = Historico.Familiar)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Historico Familiar", x = "Historico Familiar", y = "Contagem")

# Contagem de ocorrencias por Nivel de Exercicio
ggplot(treino_normalizado, aes(x = Nivel.Exercicio, fill = Nivel.Exercicio)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Nivel de Exercicio", x = "Nivel de Exercicio", y = "Contagem")

# Contagem de ocorrencias por Fumante
ggplot(treino_normalizado, aes(x = Fumante, fill = Fumante)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Fumante", x = "Fumante", y = "Contagem")

ggplot(treino_normalizado, aes(x = Risco.Hipertensao, fill = Risco.Hipertensao)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Risco.Hipertensao", x = "Risco.Hipertensao", y = "Contagem")
```

Análise da distribuição dos dados de validação

```{r}
# Histograma do Consumo de Sal normalizado
ggplot(validacao_normalizado, aes(x = Consumo.Sal)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do Consumo de Sal",
       x = "Consumo de Sal normalizado", y = "Densidade")

# Histograma da Duracao de Sono normalizad
ggplot(validacao_normalizado, aes(x = Duracao.Sono)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do Duracao Sono", x = "Duracao de Sono normalizada", y = "Densidade")

# Histograma do duração do IMC normalizado
ggplot(validacao_normalizado, aes(x = IMC)) +
  geom_histogram(fill = "orange", color = "black") +
  theme_minimal() +
  labs(title = "Distribuição do IMC",
       x = "IMC normalizado", y = "Densidade")

# Contagem de ocorrencias por Nivel de Estresse
ggplot(validacao_normalizado, aes(x = Nivel.de.Estresse, fill = Nivel.de.Estresse)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Nivel de Estresse", x = "Nivel de Estresse", y = "Contagem")

# Contagem de ocorrencias por Historico de Pressao Arterial
ggplot(validacao_normalizado, aes(x = Historico.Pressao.Arterial, fill = Historico.Pressao.Arterial)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Historico de Pressao Arterial", x = "Historico de Pressao Arterial", y = "Contagem")

# Contagem de ocorrencias por Historico Familiar
ggplot(validacao_normalizado, aes(x = Historico.Familiar, fill = Historico.Familiar)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Historico Familiar", x = "Historico Familiar", y = "Contagem")

# Contagem de ocorrencias por Nivel de Exercicio
ggplot(validacao_normalizado, aes(x = Nivel.Exercicio, fill = Nivel.Exercicio)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Nivel de Exercicio", x = "Nivel de Exercicio", y = "Contagem")

# Contagem de ocorrencias por Fumante
ggplot(validacao_normalizado, aes(x = Fumante, fill = Fumante)) +
  geom_bar() +
  theme_minimal() +
  labs(title = "Distribuição por Fumante", x = "Fumante", y = "Contagem")

```

One hot encoding de features categóricas:

```{r}
# One Hot Encoding
paste("One hot encoding para conjunto de TREINO")
dados_para_encoding_treino <- treino_normalizado
dados_para_encoding_treino$Nivel.de.Estresse <- as.factor(dados_para_encoding_treino$Nivel.de.Estresse)
one_hot <- model.matrix(~ Nivel.de.Estresse - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, one_hot)
dados_para_encoding_treino$Nivel.de.Estresse <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

dados_para_encoding_treino$Historico.Pressao.Arterial <- as.factor(dados_para_encoding_treino$Historico.Pressao.Arterial)
one_hot <- model.matrix(~ Historico.Pressao.Arterial - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, one_hot)
dados_para_encoding_treino$Historico.Pressao.Arterial <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

dados_para_encoding_treino$Nivel.Exercicio <- as.factor(dados_para_encoding_treino$Nivel.Exercicio)
one_hot <- model.matrix(~ Nivel.Exercicio - 1, data = dados_para_encoding_treino)
dados_para_encoding_treino <- cbind(dados_para_encoding_treino, one_hot)
dados_para_encoding_treino$Nivel.Exercicio <- NULL
colnames(dados_para_encoding_treino) <- gsub("-", "_", colnames(dados_para_encoding_treino))

paste("One hot encoding para conjunto de VALIDAÇÃO")

dados_para_encoding_validacao <- validacao_normalizado
dados_para_encoding_validacao$Nivel.de.Estresse <- as.factor(dados_para_encoding_validacao$Nivel.de.Estresse)
one_hot <- model.matrix(~ Nivel.de.Estresse - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, one_hot)
dados_para_encoding_validacao$Nivel.de.Estresse <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))

dados_para_encoding_validacao$Historico.Pressao.Arterial <- as.factor(dados_para_encoding_validacao$Historico.Pressao.Arterial)
one_hot <- model.matrix(~ Historico.Pressao.Arterial - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, one_hot)
dados_para_encoding_validacao$Historico.Pressao.Arterial <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))

dados_para_encoding_validacao$Nivel.Exercicio <- as.factor(dados_para_encoding_validacao$Nivel.Exercicio)
one_hot <- model.matrix(~ Nivel.Exercicio - 1, data = dados_para_encoding_validacao)
dados_para_encoding_validacao <- cbind(dados_para_encoding_validacao, one_hot)
dados_para_encoding_validacao$Nivel.Exercicio <- NULL
colnames(dados_para_encoding_validacao) <- gsub("-", "_", colnames(dados_para_encoding_validacao))
```




1.1 – Quantas amostras existem no conjunto de dados?
**Resposta:** <!-- Escreva sua resposta abaixo -->
No counto de treino temos 1349 amostras, já no validação temos 338.
<!-- Fim da resposta -->

1.2 – Existem amostras com valores ausentes? Como vocês pretendem tratar esses casos?
**Resposta:** <!-- Escreva sua resposta abaixo -->
Não observamos amostras com valores ausentes ou inválidos, tanto no conjunto de dados de treino quando no de validação.
<!-- Fim da resposta -->

1.3 – Esse conjunto de dados é balanceado? Caso não seja, como pretendem tratá-lo e por que usar essa técnica específica?
**Resposta:** <!-- Escreva sua resposta abaixo -->
Acima fizemos o plot da distribuição de dados - já normalizada para o caso de features com valores contínuos -, para cada uma das 8 faetures presentes no conjunto de dados que caracterizam as amostras: Consumo de sal, duração do sono, IMC, nível de estresse, histórico de pressão arterial, histórico familiar, nível de exercício e quantidade de fumantes. Também o fizemos para a feature alvo no modelo de predição a ser desenvolvido: Risco de hipertensão. Sobre a normalização, aplicamos a técnica de min-max.
As festures consumo de sal, duração do sono e IMC apresetam uma distribuição normal dos dados, já a feature de nível de estresse tem uma distribuição uniforme. Essas features possuem dados contínuos e a distribuição de seus valores é bem comportada, seguindo distribuição normal ou contínua, o que não afeta a qualidade do treinamento do modelo. 
O dataset também possui features categóricas, que apresentam valores discretos. Para elas montamos gráficos com a quantidade de itens por cada valor possíveis para a feature. A análise da feature de histórico familiar indica que a quantidade de pessoas com valor positivo e negativo é quase igual. A de pressão arterial possui três possíveis valores: Hipertensão, Normal e Pre-hipertensão. Isso não foi observado nas outras duas features categóricas do data set, o nível de exercício e fumante. Na primeira é possível notar uma grande diferença individuos com diferentes níveis de exercídios, temos mais de 600 indivíduos com baixo nível de exercício, por volta de 270 com alto (menos da metado da quantidade de alto) e algo am torno de 430 com moderado.Essa diferença também é notória na feature de fumantes. 
Para a nossa feature de alvo - Risco de Hipertensão - não é possível notar um grau preocupante de desbalanceamento. Por isso não é necessário aplicar nenhuma técnica para equilibrar a quantidade de indivíduos com ou sem Risco de Hipertensão.
Essa análise também foi realizada para o conjunto de dados de validação, que apresentou um perfil de distribuição, para cada uma das features, muito similiar ao de treino.
<!-- Fim da resposta -->

1.4 – Há alguma característica dos dados que pode impactar o desempenho do modelo?
O desbalanceamento das features nível de exercício e fumante, como pontuado anteriormente, pode afetar a qualidade do modelo.
**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 2 -- Regressão Logística

Treinem um modelo *baseline* de regressão logística utilizando **todas as features disponíveis**.

```{r atv2-code}
train_data <- dados_para_encoding_treino
valid_data <- dados_para_encoding_validacao
# nome da coluna que você quer mandar para o fim
coluna <- "Risco.Hipertensao"

# reordenando colunas, de forma que feature de interesse seja a ultima
train_data <- train_data[, c(setdiff(names(train_data), coluna), coluna)]
feature_names <- colnames(train_data)[1:(ncol(train_data) - 1)]

valid_data <- valid_data[, c(setdiff(names(valid_data), coluna), coluna)]

hypothesis <- getHypothesis(feature_names, 1, target = "Risco.Hipertensao")
hypothesis

# Treinamento    
model <- glmnet(train_data[,1:22], train_data$Risco.Hipertensao, family = "binomial", standardize=FALSE, maxit=1e+05, alpha=0, lambda=1e-6)
print(model$beta)
print(model$a0)

# Avaliação do Modelo
x_train <- model.matrix(hypothesis, data=train_data)
y_train <- train_data$class

x_valid <- model.matrix(hypothesis, data=valid_data)
y_valid <- valid_data$class

train_pred <- predict(model, newx=x_train[,1:22], type="response")
valid_pred <- predict(model, newx=x_valid[,1:22], type="response")

# De acordo com Threshold = 0.5, atribui valor previsto como verdadeiro ou falso 
train_class_pred <- train_pred
train_class_pred[train_pred >= 0.5] <- 1
train_class_pred[train_pred < 0.5]  <- 0

valid_class_pred <- valid_pred
valid_class_pred[valid_pred >= 0.5] <- 1
valid_class_pred[valid_pred < 0.5]  <- 0

# gera o Loss para as bases de treino e validação
train_losses <- getLoss(train_data$Risco.Hipertensao, train_class_pred)
valid_losses <- getLoss(valid_data$Risco.Hipertensao, valid_class_pred)

cat("Train\n")
print(train_losses)

cat("Valid\n")
print(valid_losses)

# gera matriz de confusão para dados de treino e validação
train_cm <- confusionMatrix(data = as.factor(train_class_pred), reference = as.factor(train_data$Risco.Hipertensao), positive='1')
valid_cm <- confusionMatrix(data = as.factor(valid_class_pred), reference = as.factor(valid_data$Risco.Hipertensao), positive='1')

# Calculando as métricas para o conjunto de treino
train_metrics = calculateMetrics(train_cm$table)

# Calculando as métricas para o conjunto de validação
valid_metrics = calculateMetrics(valid_cm$table)

# Organizando os resultados em um dataframe
results_baseline <- data.frame(
  Train  = train_metrics,
  Valid  = valid_metrics
)

# Formatando os resultados para melhor leitura
results_baseline$Train <- as.numeric(results_baseline$Train)
results_baseline$Valid <- as.numeric(results_baseline$Valid)

# Evitando notação científica na exibição dos resultados
results_baseline$Train <- format(results_baseline$Train, scientific = FALSE)
results_baseline$Valid <- format(results_baseline$Valid, scientific = FALSE)

# Exibindo os resultados
results_baseline
```

2.1 – O modelo baseline foi suficiente para resolver o problema? Quais métricas de avaliação vocês utilizaram para justificar a resposta?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 3 -- Soluções alternativas da Regressão Logística

Implementem soluções alternativas baseadas em regressão logística, seja através da combinação das *features* **ou** de modelos polinomiais para melhorar o resultado do *baseline*. Comparem suas soluções reportando métricas de interesse no **conjunto de validação**.

```{r atv3-code}
# Hipóteses alternativas

# Treinamento

# Curva de viés e variância

# Métricas de avaliação

```

3.1 – Quais foram os critérios utilizados para selecionar a técnica alternativa?

3.2 – Alguma combinação gerou um impacto positivo ou negativo significativo no desempenho do modelo? Por quê?

3.3 – Existe alguma relação entre viés e variância no seu modelo ao modificar o modelo (seja por combinações de *features* ou polinomiais)?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 4 -- Regularização

Escolham um dos modelos do item anterior e variem o fator de regularização ($\lambda$). Avaliem a curva de viés e variância e reportem a matriz de confusão relativa para o melhor modelo no conjunto de validação.

```{r atv4-code}
# Busca de hiperparâmetros

# Treinamento

# Curva de viés e variância

# Métricas de avaliação
```

4.1 – Como a regularização afetou o desempenho do modelo?

4.2 – Foi utilizada regularização Lasso ou Ridge? Por quê?

4.3 – Houve um ponto ótimo onde o erro foi minimizado? Como vocês identificaram esse ponto?

4.4 – Em quais regiões da curva de viés e variância foi possível identificar *underfitting* e *overfitting*?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 5 -- Árvore de Decisão

Treinem um modelo *baseline 2* de árvore de decisão **todas as features disponíveis**.

```{r atv5-code}
# Treinamento    

# Avaliação do Modelo 

```

5.1 – O modelo *baseline 2* foi suficiente para resolver o problema? Quais métricas de avaliação vocês utilizaram para justificar a resposta?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 6 -- Profundidade da Árvore de Decisão

Treinem árvores de decisão variando a profundidade máxima. Mostrem a curva de viés e variância, no qual o eixo X é a profundidade e o eixo Y é o erro ou uma métrica de interesse.

```{r atv6-code}
# Busca de hiperparâmetros

# Treinamento

# Curva de viés e variância

# Métricas de avaliação

```

6.1 – Como a profundidade afetou o desempenho do modelo?

6.2 – Houve um ponto ótimo onde o erro foi minimizado? Como vocês identificaram esse ponto?

6.3 – Em quais regiões da curva de viés e variância foi possível identificar *underfitting* e *overfitting*?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 7 -- Soluções alternativas da Árvore de Decisão

Explorem pelo menos dois subconjuntos de *features* para treinar diferentes árvores de decisão.

**Dica: observem a importância de cada *feature* por meio do atributo *variable.importance*.**

```{r atv7-code}
# Hipóteses alternativas

# Treinamento

# Métricas de avaliação
```

7.1 – Quais foram os critérios utilizados para selecionar a técnica alternativa?

7.2 – Alguma combinação gerou um impacto positivo ou negativo significativo no desempenho do modelo? Por quê?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 8 -- Floresta Aleatórias

Treinem *N* florestas aleatórias, variando o número de árvores. Mostrem a curva de viés e variância, na qual o eixo X é a profundidade e o eixo Y é o erro ou uma métrica de interesse.

```{r atv8-code}
# Busca de hiperparâmetros

# Treinamento

# Curva de viés e variância

# Métricas de avaliação

```

8.1 – Como a quantidade de árvores afetou o desempenho do modelo?

8.2 – Houve um ponto ótimo onde o erro foi minimizado? Como vocês identificaram esse ponto?

8.3 – Em quais regiões da curva de viés e variância foi possível identificar *underfitting* e *overfitting*?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 9 -- (Opcional) Ensembles

Implementem manualmente um protocolo de *ensemble* (e.g., *Bagging*, *Pasting* ou *Random Forest*), ajustando os parâmetros dessas técnicas.

```{r atv9-code}
# Treinamento

# Métricas de avaliaçao
```

9.1 – Qual foi o critério para a decisão da técnica utilizada?

9.2 – O resultado foi melhor comparado com outros cenários já testados?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Tarefa 10 -- Conjunto de Teste

Após identificar o melhor modelo, utilizem-no para fazer previsões no conjunto de teste e avaliem o seu desempenho.

```{r atv10-code}
# Predição no conjunto de teste

# Métricas de avaliação

# Métricas de avaliação
```

10.1 – Qual foi o critério adotado para definir o melhor modelo?

10.2 – Como os resultados no conjunto de teste se comparam aos obtidos no conjunto de validação? Houve algum indício degradação ou melhora do modelo?

10.4 – Expliquem a diferença entre os modelos e o porquê que estas diferenças levaram a resultados piores ou melhores.

10.5 – Considerando as diferentes abordagens testadas, quais estratégias poderiam ser aplicadas para melhorar ainda mais o desempenho do modelo?

**Resposta:** <!-- Escreva sua resposta abaixo -->

<!-- Fim da resposta -->

# Observações Finais

Justifiquem suas escolhas com base em evidências (métricas, gráficos, hipóteses teóricas).

A clareza na comunicação dos resultados é mais importante do que a qualidade do modelo!
