---
title: INF0615 -- Aprendizado Supervisionado I
output: pdf_document
subtitle: Exercício 10 - Open-set
---

```{r setup, include = FALSE}

knitr::opts_chunk$set(
  echo    = TRUE,   # Exibir código nos chunks
  error   = FALSE,  # Ocultar mensagens de erro
  message = FALSE,  # Ocultar mensagens informativas
  warning = FALSE,  # Ocultar avisos
  tidy    = FALSE   # Não reformatar automaticamente o código
)

options(digits = 4) # Definição do número de casas decimais padrão
```

Neste exercício, exploraremos conceitos de aprendizado supervisionado aplicados à open set.

------------------------------------------------------------------------

## Módulo 0: Instalando Dependências

Antes de prosseguir, verifique se as bibliotecas necessárias estão instaladas. Caso não estejam, remova o `#` das linhas abaixo para instalá-las:

```{r install-packages, eval = FALSE}
# install.packages("glmnet")
# install.packages("caret")
```

------------------------------------------------------------------------

## Módulo 1: Configuração do Ambiente

Carregue as bibliotecas necessárias e define uma semente aleatória para reprodutibilidade:

```{r}
library(glmnet)    # Para modelagem de regressão
library(caret)     # Para treinamento de modelos

set.seed(42)  # Garante reprodutibilidade dos resultados
```

------------------------------------------------------------------------

## Módulo 2: Carregamento do Dataset

Carregue os conjuntos de dados de **treinamento** e **validação**, que serão utilizados para treinar e avaliar os modelos:

```{r}
train_data <- read.csv("Known_training_set.csv", stringsAsFactors = TRUE)
valid_data <- read.csv("Known_validation_set.csv", stringsAsFactors = TRUE)
```

### Módulo 2.1: Explorando os Dados

A seguir, analisamos algumas informações básicas sobre os conjuntos de dados.

#### Módulo 2.1.1: Dados de Treinamento

```{r}
# Visualiza as primeiras linhas do dataset
head(train_data)

# Exibe as dimensões do dataset
cat("Amostras:", nrow(train_data), "Features:", ncol(train_data) - 1, "\n")

# Resumo estatístico dos dados
summary(train_data)

# Verifica a existência de valores ausentes
if (any(is.na(train_data))) {
  cat("Aviso: Existem valores ausentes no conjunto de treinamento.\n")
} else {
  cat("Nenhum valor ausente encontrado no conjunto de treinamento.\n")
}
```

#### Módulo 2.1.2: Dados de Validação

```{r}
# Visualiza as primeiras linhas do dataset
head(valid_data)

# Exibe as dimensões do dataset
cat("Amostras:", nrow(valid_data), "Features:", ncol(valid_data) - 1, "\n")

# Resumo estatístico dos dados
summary(valid_data)

# Verifica a existência de valores ausentes
if (any(is.na(valid_data))) {
  cat("Aviso: Existem valores ausentes no conjunto de validação.\n")
} else {
  cat("Nenhum valor ausente encontrado no conjunto de validação.\n")
}
```

### Etapa 2.2: Normalização dos Dados

Normalização é um processo que ajusta os valores das features para uma escala comum, melhorando a performance dos modelos. A formula do Z-norm é a seguinte:

$$x_{MinMax} = \frac{x - min(x)}{max(x) - min(x)}$$

```{r}
# Calculando a média e o desvio padrão para normalização
min_features <- apply(train_data[, 1:(ncol(train_data)-1)], 2, min)
max_features <- apply(train_data[, 1:(ncol(train_data)-1)], 2, max)
diff         <- max_features - min_features

print("Valores mínimos")
print(min_features)
print("Valores máximos")
print(max_features)
print("Diferença entre máximos e mínimos")
print(diff)
```

```{r}
# Aplicando a normalização Min-Max nos dados de treino e validação
train_data[, 1:(ncol(train_data)-1)] <- sweep(train_data[, 1:(ncol(train_data)-1)], 2, min_features, "-")
train_data[, 1:(ncol(train_data)-1)] <- sweep(train_data[, 1:(ncol(train_data)-1)], 2, diff, "/")

valid_data[, 1:(ncol(valid_data)-1)] <- sweep(valid_data[, 1:(ncol(valid_data)-1)], 2, min_features, "-")
valid_data[, 1:(ncol(valid_data)-1)] <- sweep(valid_data[, 1:(ncol(valid_data)-1)], 2, diff, "/")
```

```{r}
summary(train_data)
```

------------------------------------------------------------------------

## Módulo 3: Protocolo One-Contra-Todos

Vamos treinar `N` modelos, no qual `N` se refere a quantidade de classes

```{r}
hypothesis <- formula(target ~ .)
```

### Módulo 3.1: South America VS Rest

```{r}
positive_train_data <- train_data[train_data$continent == "South America",]
negative_train_data <- train_data[train_data$continent != "South America",]

# Remove a coluna continente
positive_train_data$continent <- NULL
negative_train_data$continent <- NULL 

# Refazemos os labels, no qual 1 representa amostras da South America e 0 o restante
positive_train_data$target <- 1
negative_train_data$target <- 0

train <- rbind(positive_train_data, negative_train_data)
table(train$target)
```

```{r}
x_train <- model.matrix(hypothesis, train)
y_train <- train$target

logReg01 <-  glmnet(x_train, y_train,  family="binomial", 
                    standardize = FALSE, alpha=0, lambda = 1e-6)
```

### Módulo 3.2: Central America VS Rest

```{r}
positive_train_data <- train_data[train_data$continent == "Central America",]
negative_train_data <- train_data[train_data$continent != "Central America",]

# Remove a coluna continente
positive_train_data$continent <- NULL
negative_train_data$continent <- NULL 

# Refazemos os labels, no qual 1 representa amostras da Central America e 0 o restante
positive_train_data$target <- 1
negative_train_data$target <- 0

train <- rbind(positive_train_data, negative_train_data)
table(train$target)
```

```{r}
x_train <- model.matrix(hypothesis, train)
y_train <- train$target

logReg02 <-  glmnet(x_train, y_train,  family="binomial", 
                    standardize = FALSE, alpha=0, lambda = 1e-6)
```

### Módulo 3.3: Eastern Africa VS Rest

```{r}
positive_train_data <- train_data[train_data$continent == "Eastern Africa",]
negative_train_data <- train_data[train_data$continent != "Eastern Africa",]

# Remove a coluna continente
positive_train_data$continent <- NULL
negative_train_data$continent <- NULL 

# Refazemos os labels, no qual 1 representa amostras da Eastern Africa e 0 o restante
positive_train_data$target <- 1
negative_train_data$target <- 0

train <- rbind(positive_train_data, negative_train_data)
table(train$target)
```

```{r}
x_train <- model.matrix(hypothesis, train)
y_train <- train$target

logReg03 <-  glmnet(x_train, y_train,  family="binomial", 
                    standardize = FALSE, alpha=0, lambda = 1e-6)
```

### Módulo 3.4: South-Eastern Asia VS Rest

```{r}
positive_train_data <- train_data[train_data$continent == "South-Eastern Asia",]
negative_train_data <- train_data[train_data$continent != "South-Eastern Asia",]

# Remove a coluna continente
positive_train_data$continent <- NULL
negative_train_data$continent <- NULL 

# Refazemos os labels, no qual 1 representa amostras da South-Eastern Asia e 0 o restante
positive_train_data$target <- 1
negative_train_data$target <- 0

train <- rbind(positive_train_data, negative_train_data)
table(train$target)
```

```{r}
x_train <- model.matrix(hypothesis, train)
y_train <- train$target

logReg04 <-  glmnet(x_train, y_train,  family="binomial", 
                    standardize = FALSE, alpha=0, lambda = 1e-6)
```

### Módulo 3.5: Western Europe VS Rest

```{r}
positive_train_data <- train_data[train_data$continent == "Western Europe",]
negative_train_data <- train_data[train_data$continent != "Western Europe",]

# Remove a coluna continente
positive_train_data$continent <- NULL
negative_train_data$continent <- NULL 

# Refazemos os labels, no qual 1 representa amostras da Western Europe e 0 o restante
positive_train_data$target <- 1
negative_train_data$target <- 0

train <- rbind(positive_train_data, negative_train_data)
table(train$target)
```

```{r}
x_train <- model.matrix(hypothesis, train)
y_train <- train$target

logReg05 <-  glmnet(x_train, y_train,  family="binomial", 
                    standardize = FALSE, alpha=0, lambda = 1e-6)
```

### Módulo 3.6: Predição

Uma vez que o modelo está treinado, podemos realizar previsões tanto para os dados de treino quanto para os dados de validação.

```{r}
# Criamos a coluna target para o conjunto de validação. Para controle, colocamos o valor -1
valid_data$target <- -1

# Armazenamos o valor Ground Truth em outra variável
gt_valid_data        <- valid_data$continent
valid_data$continent <- NULL
```

```{r}
x_val <- model.matrix(hypothesis, valid_data)

valPred01 <- predict(logReg01, newx = x_val, type="response")
valPred02 <- predict(logReg02, newx = x_val, type="response")
valPred03 <- predict(logReg03, newx = x_val, type="response")
valPred04 <- predict(logReg04, newx = x_val, type="response")
valPred05 <- predict(logReg05, newx = x_val, type="response")
```

```{r}
# Criando a matriz de previsões combinando os vetores de probabilidade
valPred <- cbind(valPred01, valPred02, valPred03, valPred04, valPred05)

# Criando a matriz de classes (one-hot encoding)
classVectors <- diag(5)

# Nomeando as colunas com as classes correspondentes
colnames(classVectors) <- c("South America", "Central America",
                            "Eastern Africa", "South-Eastern Asia", 
                            "Western Europe")

# Criando uma matriz vazia para armazenar as distâncias
valDists <- c()

# Iteramos sobre cada linha das previsões para calcular a distância de Manhattan
for (idx in 1:nrow(valPred)) {
    dist <- apply(classVectors, 1, 
                  function(x) { 
                      dist(rbind(valPred[idx,], x), method = "manhattan")
                  })
    valDists <- rbind(valDists, dist)
}

# Nomeando as colunas da matriz de distâncias
colnames(valDists) <- c("South America", "Central America",
                        "Eastern Africa", "South-Eastern Asia", 
                        "Western Europe")

# Obtendo a classe com menor distância em cada linha
valClass <- colnames(valDists)[apply(valDists, 1, which.min)]

# Exibindo as classes preditas
print(valClass)
```

### Módulo 3.7: Matriz de Confusão

A matriz de confusão é uma tabela utilizada para descrever o desempenho de um modelo de classificação. A partir dessa matriz, podemos calcular métricas importantes como precisão, recall e accuracy.

```{r}
# Calcula a matriz de confusao relativa 
calculaMatrizConfusaoRelativa <- function(cm, num_classes=5){
    
    # Aplicamos a transposicao para garantir que a referencia
    # fique nas linhas e a predicao nas colunas
    cm_absolute = t(cm$table)
    
    # SEMPRE construam e reportem a matriz de confusao relativa!
    cm_relative = cm_absolute
    
    for(i in 1:num_classes){
        cm_relative[i,] = round(cm_absolute[i,]/sum(cm_absolute[i,]), digits=2)
    }
    
    return(cm_relative)  
}
```

```{r}
cat("Valid\n")
cm <- confusionMatrix(data=as.factor(valClass), 
                      reference=as.factor(gt_valid_data))

valid_cm_relative <- calculaMatrizConfusaoRelativa(cm)
valid_cm_relative

cat("\nBalanced Accuracy = ", mean(diag(valid_cm_relative)), '\n')
```

## Módulo 4: Open Set

```{r}
valid_data_open_set <- read.csv("Unknown_validation_set.csv", stringsAsFactors = T)
valid_data_open_set[,1:(ncol(valid_data_open_set)-1)] <- sweep(valid_data_open_set[,1:(ncol(valid_data_open_set)-1)], 2, min_features, "-")
valid_data_open_set[,1:(ncol(valid_data_open_set)-1)] <- sweep(valid_data_open_set[,1:(ncol(valid_data_open_set)-1)], 2, diff, "/")
summary(valid_data_open_set)
```

```{r}
# Atribuindo -1 à coluna target, pois ela será prevista
valid_data_open_set$target <- -1

# Armazenando o rótulo verdadeiro das amostras
gt_valid_data_open_set <- valid_data_open_set$continent

# Removendo a coluna "continent"
valid_data_open_set$continent <- NULL

# Criando matriz de características para validação
x_val_openset <- model.matrix(hypothesis, valid_data_open_set)

# Obtendo previsões dos cinco modelos treinados
valPredOpenSet01 <- predict(logReg01, newx = x_val_openset, type="response")
valPredOpenSet02 <- predict(logReg02, newx = x_val_openset, type="response")
valPredOpenSet03 <- predict(logReg03, newx = x_val_openset, type="response")
valPredOpenSet04 <- predict(logReg04, newx = x_val_openset, type="response")
valPredOpenSet05 <- predict(logReg05, newx = x_val_openset, type="response")
```

```{r}
# Combinando as previsões em uma única matriz
valPredOpenSet <- cbind(valPredOpenSet01, valPredOpenSet02, valPredOpenSet03, 
                        valPredOpenSet04, valPredOpenSet05)

colnames(valPredOpenSet) <- c("Modelo 1", "Modelo 2", "Modelo 3", "Modelo 4", "Modelo 5")
```

```{r}
# Obtendo a maior probabilidade predita para cada amostra
unknown_MaxProb <- apply(valPredOpenSet, 1, max)
known_MaxProb <- apply(valPred, 1, max)

# Exibindo as três primeiras probabilidades máximas
print(unknown_MaxProb[1:3])
```

```{r}
# Definição de thresholds variando entre 0.5 e 0.9
thresholdSearching <- seq(0.5, 0.9, length=10)

# MaxProbs >= threshold ----> Known Class
# MaxProbs < threshold  ----> Unknown Class

# Inicializando vetores de acurácia
accK <- c()
accUk <- c()

for (idx in 1:length(thresholdSearching)) {
    t <- thresholdSearching[idx]
    
    accK[idx]  <- sum(known_MaxProb >= t) / length(known_MaxProb)
    accUk[idx] <- sum(unknown_MaxProb < t) / length(unknown_MaxProb)
}

# Acurácia média entre classes conhecidas e desconhecidas
acc <- (accK + accUk) / 2.0

```

```{r}
# Plot das acurácias para diferentes thresholds
plot(accK, type="o", col="blue", xaxt="n", xlab="t", ylab="Acc", ylim=c(0.0,1.0), main="Acurácia x Threshold")
axis(1, at=1:length(thresholdSearching), labels=thresholdSearching, cex.axis=0.5, las=2)

points(accUk, col="red", pch="*")
lines(accUk, col="red", lty=2)

points(acc, col="green", pch="*")
lines(acc, col="green", lty=3)

legend(7, 0.2, legend=c("Acurácia Conhecida", "Acurácia Desconhecida", "Acurácia Média"), 
       col=c("blue", "red", "green"), pch=c("__"), cex=0.7, pt.cex=1)


# Definição do threshold ideal
openSetThreshold <- 0.75

```

```{r}
# Carregando o conjunto de teste
testSet <- read.csv("OpenSet_test_set.csv")

# Normalizando os dados
testSet[,1:(ncol(testSet)-1)] <- sweep(testSet[,1:(ncol(testSet)-1)], 2, min_features, "-")
testSet[,1:(ncol(testSet)-1)] <- sweep(testSet[,1:(ncol(testSet)-1)], 2, diff, "/")

# Exibindo um resumo dos dados
summary(testSet)

```

```{r}
# Definindo -1 na coluna target
testSet$target <- -1

# Armazenando rótulos reais
gt_testSet <- testSet$continent

# Renomeando classes desconhecidas
gt_testSet[!(gt_testSet %in% colnames(classVectors))] <- "yUnknown"
gt_testSet <- as.factor(gt_testSet)

# Removendo a coluna "continent"
testSet$continent <- NULL
```

```{r}
# Criando matriz de características para o conjunto de teste
x_test <- model.matrix(hypothesis, testSet)

# Obtendo previsões dos cinco modelos treinados
testPred01 <- predict(logReg01, newx = x_test, type="response")
testPred02 <- predict(logReg02, newx = x_test, type="response")
testPred03 <- predict(logReg03, newx = x_test, type="response")
testPred04 <- predict(logReg04, newx = x_test, type="response")
testPred05 <- predict(logReg05, newx = x_test, type="response")

# Combinando as previsões em uma única matriz
testPred <- cbind(testPred01, testPred02, testPred03, 
                  testPred04, testPred05)

# Obtendo a maior probabilidade predita por amostra
test_MaxProb <- apply(testPred, 1, max)
```

```{r}
testDists <- c()
for (idx in 1:nrow(testPred)) {
    distances <- apply(classVectors, 1, 
                       function(x) { 
                           dist(rbind(testPred[idx,], x), method="manhattan")
                       })
    testDists <- rbind(testDists, distances)
}
```

```{r}
testClass <- c()
for (idx in 1:nrow(testPred)) {
    testClass[idx] <- ifelse(test_MaxProb[idx] >= openSetThreshold,
                             colnames(classVectors)[which.min(testDists[idx,])],
                             "yUnknown")
}
```

```{r}
# Criando matriz de confusão
cm <- confusionMatrix(data=as.factor(testClass), reference=as.factor(gt_testSet))

# Calculando matriz de confusão relativa
cm_relative <- calculaMatrizConfusaoRelativa(cm, num_classes=6)
print(cm_relative)
```

```{r}
# Exibindo acurácia balanceada por classe
print(diag(cm_relative))

# Calculando a acurácia balanceada geral
acc_bal <- mean(diag(cm_relative))
print(acc_bal)
```
